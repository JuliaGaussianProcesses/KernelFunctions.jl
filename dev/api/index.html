<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · KernelFunctions</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KernelFunctions</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../userguide/">User Guide</a></li><li><a class="tocitem" href="../example/">Examples</a></li><li><a class="tocitem" href="../kernels/">Kernel Functions</a></li><li><a class="tocitem" href="../transform/">Transform</a></li><li><a class="tocitem" href="../metrics/">Metrics</a></li><li><a class="tocitem" href="../theory/">Theory</a></li><li><a class="tocitem" href="../create_kernel/">Custom Kernels</a></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li><a class="tocitem" href="#Module"><span>Module</span></a></li><li><a class="tocitem" href="#Base-Kernels-API"><span>Base Kernels API</span></a></li><li><a class="tocitem" href="#Composite-Kernels"><span>Composite Kernels</span></a></li><li><a class="tocitem" href="#Transforms"><span>Transforms</span></a></li><li><a class="tocitem" href="#Functions"><span>Functions</span></a></li><li><a class="tocitem" href="#Utilities"><span>Utilities</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Library"><a class="docs-heading-anchor" href="#API-Library">API Library</a><a id="API-Library-1"></a><a class="docs-heading-anchor-permalink" href="#API-Library" title="Permalink"></a></h1><hr/><ul><li><a href="#API-Library">API Library</a></li><ul><li><a href="#Module">Module</a></li><li><a href="#Base-Kernels-API">Base Kernels API</a></li><li><a href="#Composite-Kernels">Composite Kernels</a></li><li><a href="#Transforms">Transforms</a></li><li><a href="#Functions">Functions</a></li><li><a href="#Utilities">Utilities</a></li><li><a href="#Index">Index</a></li></ul></ul><h2 id="Module"><a class="docs-heading-anchor" href="#Module">Module</a><a id="Module-1"></a><a class="docs-heading-anchor-permalink" href="#Module" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelFunctions" href="#KernelFunctions.KernelFunctions"><code>KernelFunctions.KernelFunctions</code></a> — <span class="docstring-category">Module</span></header><section><div><p>KernelFunctions. <a href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl">Github</a> <a href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/stable/">Documentation</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/KernelFunctions.jl#L1-L4">source</a></section></article><h2 id="Base-Kernels-API"><a class="docs-heading-anchor" href="#Base-Kernels-API">Base Kernels API</a><a id="Base-Kernels-API-1"></a><a class="docs-heading-anchor-permalink" href="#Base-Kernels-API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ConstantKernel" href="#KernelFunctions.ConstantKernel"><code>KernelFunctions.ConstantKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ConstantKernel(; c=1.0)</code></pre><p>Kernel function always returning a constant value <code>c</code></p><pre><code class="language-none">    κ(x,y) = c</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/constant.jl#L43-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.WhiteKernel" href="#KernelFunctions.WhiteKernel"><code>KernelFunctions.WhiteKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WhiteKernel()</code></pre><pre><code class="language-none">    κ(x,y) = δ(x,y)</code></pre><p>Kernel function working as an equivalent to add white noise. Can also be called via <code>EyeKernel()</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/constant.jl#L19-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.EyeKernel" href="#KernelFunctions.EyeKernel"><code>KernelFunctions.EyeKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">EyeKernel()</code></pre><p>See <a href="#KernelFunctions.WhiteKernel"><code>WhiteKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/constant.jl#L29-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ZeroKernel" href="#KernelFunctions.ZeroKernel"><code>KernelFunctions.ZeroKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ZeroKernel()</code></pre><p>Create a kernel that always returning zero</p><pre><code class="language-none">    κ(x,y) = 0.0</code></pre><p>The output type depends of <code>x</code> and <code>y</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/constant.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.CosineKernel" href="#KernelFunctions.CosineKernel"><code>KernelFunctions.CosineKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CosineKernel()</code></pre><p>The cosine kernel is a stationary kernel for a sinusoidal given by</p><pre><code class="language-none">    κ(x,y) = cos( π * (x-y) )</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/cosine.jl#L1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.SqExponentialKernel" href="#KernelFunctions.SqExponentialKernel"><code>KernelFunctions.SqExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SqExponentialKernel()</code></pre><p>The squared exponential kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = exp(-‖x-y‖²)</code></pre><p>Can also be called via <code>SEKernel</code>, <code>GaussianKernel</code> or <code>SEKernel</code>. See also <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a> for a related form of the kernel or <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a> for a generalization.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/exponential.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ExponentialKernel" href="#KernelFunctions.ExponentialKernel"><code>KernelFunctions.ExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ExponentialKernel()</code></pre><p>The exponential kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = exp(-‖x-y‖)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/exponential.jl#L27-L34">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GammaExponentialKernel" href="#KernelFunctions.GammaExponentialKernel"><code>KernelFunctions.GammaExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GammaExponentialKernel(; γ = 2.0)</code></pre><p>The γ-exponential kernel is an isotropic Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = exp(-‖x-y‖^(2γ))</code></pre><p>Where <code>γ &gt; 0</code>, (the keyword <code>γ</code> can be replaced by <code>gamma</code>) For <code>γ = 1</code>, see <code>SqExponentialKernel</code> and <code>γ = 0.5</code>, see <code>ExponentialKernel</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/exponential.jl#L48-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ExponentiatedKernel" href="#KernelFunctions.ExponentiatedKernel"><code>KernelFunctions.ExponentiatedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ExponentiatedKernel()</code></pre><p>The exponentiated kernel is a Mercer kernel given by:</p><pre><code class="language-none">    κ(x,y) = exp(xᵀy)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/exponentiated.jl#L1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.FBMKernel" href="#KernelFunctions.FBMKernel"><code>KernelFunctions.FBMKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FBMKernel(; h::Real=0.5)</code></pre><p>Fractional Brownian motion kernel with Hurst index <code>h</code> from (0,1) given by</p><pre><code class="language-none">    κ(x,y) =  ( |x|²ʰ + |y|²ʰ - |x-y|²ʰ ) / 2</code></pre><p>For <code>h=1/2</code>, this is the Wiener Kernel, for <code>h&gt;1/2</code>, the increments are positively correlated and for <code>h&lt;1/2</code> the increments are negatively correlated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/fbm.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GaborKernel" href="#KernelFunctions.GaborKernel"><code>KernelFunctions.GaborKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GaborKernel(; ell::Real=1.0, p::Real=1.0)</code></pre><p>Gabor kernel with lengthscale <code>ell</code> and period <code>p</code>. Given by</p><div>\[    κ(x,y) =  h(x-z), h(t) = exp(-sum(t.^2./(ell.^2)))*cos(pi*sum(t./p))\]</div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/gabor.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.MaternKernel" href="#KernelFunctions.MaternKernel"><code>KernelFunctions.MaternKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MaternKernel(; ν = 1.0)</code></pre><p>The matern kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = 2^{1-ν}/Γ(ν)*(√(2ν)‖x-y‖)^ν K_ν(√(2ν)‖x-y‖)</code></pre><p>For <code>ν=n+1/2, n=0,1,2,...</code> it can be simplified and you should instead use <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a> for <code>n=0</code>, <a href="#KernelFunctions.Matern32Kernel"><code>Matern32Kernel</code></a>, for <code>n=1</code>, <a href="#KernelFunctions.Matern52Kernel"><code>Matern52Kernel</code></a> for <code>n=2</code> and <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> for <code>n=∞</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/matern.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Matern32Kernel" href="#KernelFunctions.Matern32Kernel"><code>KernelFunctions.Matern32Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Matern32Kernel()</code></pre><p>The matern 3/2 kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = (1+√(3)‖x-y‖)exp(-√(3)‖x-y‖)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/matern.jl#L32-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Matern52Kernel" href="#KernelFunctions.Matern52Kernel"><code>KernelFunctions.Matern52Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Matern52Kernel()</code></pre><p>The matern 5/2 kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = (1+√(5)‖x-y‖ + 5/3‖x-y‖^2)exp(-√(5)‖x-y‖)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/matern.jl#L48-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.NeuralNetworkKernel" href="#KernelFunctions.NeuralNetworkKernel"><code>KernelFunctions.NeuralNetworkKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NeuralNetworkKernel()</code></pre><p>Neural network kernel function.</p><div>\[    κ(x, y) =  asin(x&#39; * y / sqrt[(1 + x&#39; * x) * (1 + y&#39; * y)])\]</div><p><strong>Significance</strong></p><p>Neal (1996) pursued the limits of large models, and showed that a Bayesian neural network becomes a Gaussian process with a <strong>neural network kernel</strong> as the number of units approaches infinity. Here, we give the neural network kernel for single hidden layer Bayesian neural network with erf (Error Function) as activation function.</p><p><strong>References:</strong></p><ul><li><a href="http://www.gaussianprocess.org/gpml/chapters/RW4.pdf">GPML Pg 105</a></li><li><a href="https://www.cs.toronto.edu/~radford/bnn.book.html">Neal(1996)</a></li><li><a href="http://www.cs.cmu.edu/~andrewgw/andrewgwthesis.pdf">Andrew Gordon&#39;s Thesis Pg 45</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/nn.jl#L1-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.LinearKernel" href="#KernelFunctions.LinearKernel"><code>KernelFunctions.LinearKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinearKernel(; c = 0.0)</code></pre><p>The linear kernel is a Mercer kernel given by</p><pre><code class="language-none">    κ(x,y) = xᵀy + c</code></pre><p>Where <code>c</code> is a real number</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/polynomial.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PolynomialKernel" href="#KernelFunctions.PolynomialKernel"><code>KernelFunctions.PolynomialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PolynomialKernel(; d = 2.0, c = 0.0)</code></pre><p>The polynomial kernel is a Mercer kernel given by</p><pre><code class="language-none">    κ(x,y) = (xᵀy + c)^d</code></pre><p>Where <code>c</code> is a real number, and <code>d</code> is a shape parameter bigger than 1. For <code>d = 1</code> see <a href="#KernelFunctions.LinearKernel"><code>LinearKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/polynomial.jl#L23-L31">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PiecewisePolynomialKernel" href="#KernelFunctions.PiecewisePolynomialKernel"><code>KernelFunctions.PiecewisePolynomialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PiecewisePolynomialKernel{V}(maha::AbstractMatrix)</code></pre><p>Piecewise Polynomial covariance function with compact support, V = 0,1,2,3. The kernel functions are 2v times continuously differentiable and the corresponding processes are hence v times  mean-square differentiable. The kernel function is:</p><div>\[    κ(x, y) = max(1 - r, 0)^(j + V) * f(r, j) with j = floor(D / 2) + V + 1\]</div><p>where <code>r</code> is the Mahalanobis distance mahalanobis(x,y) with <code>maha</code> as the metric.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/piecewisepolynomial.jl#L1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.MahalanobisKernel" href="#KernelFunctions.MahalanobisKernel"><code>KernelFunctions.MahalanobisKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MahalanobisKernel(P::AbstractMatrix)</code></pre><p>Mahalanobis distance-based kernel given by</p><div>\[    κ(x,y) =  exp(-r^2), r^2 = maha(x,P,y) = (x-y)&#39;*inv(P)*(x-y)\]</div><p>where the matrix P is the metric.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/maha.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.RationalQuadraticKernel" href="#KernelFunctions.RationalQuadraticKernel"><code>KernelFunctions.RationalQuadraticKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RationalQuadraticKernel(; α = 2.0)</code></pre><p>The rational-quadratic kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y)=(1+||x−y||²/α)^(-α)</code></pre><p>where <code>α</code> is a shape parameter of the Euclidean distance. Check <a href="#KernelFunctions.GammaRationalQuadraticKernel"><code>GammaRationalQuadraticKernel</code></a> for a generalization.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/rationalquad.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GammaRationalQuadraticKernel" href="#KernelFunctions.GammaRationalQuadraticKernel"><code>KernelFunctions.GammaRationalQuadraticKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>GammaRationalQuadraticKernel([ρ=1.0[,α=2.0[,γ=2.0]]])</code> The Gamma-rational-quadratic kernel is an isotropic Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y)=(1+ρ^(2γ)||x−y||^(2γ)/α)^(-α)</code></pre><p>where <code>α</code> is a shape parameter of the Euclidean distance and <code>γ</code> is another shape parameter.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/rationalquad.jl#L23-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.spectral_mixture_kernel" href="#KernelFunctions.spectral_mixture_kernel"><code>KernelFunctions.spectral_mixture_kernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spectral_mixture_kernel(
    h::Kernel=SqExponentialKernel(),
    αs::AbstractVector{&lt;:Real},
    γs::AbstractMatrix{&lt;:Real},
    ωs::AbstractMatrix{&lt;:Real},
)</code></pre><p>where αs are the weights of dimension (A, ), γs is the covariance matrix of dimension (D, A) and ωs are the mean vectors and is of dimension (D, A). Here, D is input dimension and A is the number of spectral components.</p><p><code>h</code> is the kernel, which defaults to <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> if not specified.</p><p>Generalised Spectral Mixture kernel function. This family of functions is  dense in the family of stationary real-valued kernels with respect to the pointwise convergence.[1]</p><div>\[   κ(x, y) = αs&#39; (h(-(γs&#39; * t)^2) .* cos(π * ωs&#39; * t), t = x - y\]</div><p><strong>References:</strong></p><pre><code class="language-none">[1] Generalized Spectral Kernels, by Yves-Laurent Kom Samo and Stephen J. Roberts
[2] SM: Gaussian Process Kernels for Pattern Discovery and Extrapolation,
        ICML, 2013, by Andrew Gordon Wilson and Ryan Prescott Adams,
[3] Covariance kernels for fast automatic pattern discovery and extrapolation
    with Gaussian processes, Andrew Gordon Wilson, PhD Thesis, January 2014.
    http://www.cs.cmu.edu/~andrewgw/andrewgwthesis.pdf
[4] http://www.cs.cmu.edu/~andrewgw/pattern/.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/sm.jl#L1-L31">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.spectral_mixture_product_kernel" href="#KernelFunctions.spectral_mixture_product_kernel"><code>KernelFunctions.spectral_mixture_product_kernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spectral_mixture_product_kernel(
    h::Kernel=SqExponentialKernel(),
    αs::AbstractMatrix{&lt;:Real},
    γs::AbstractMatrix{&lt;:Real},
    ωs::AbstractMatrix{&lt;:Real},
)</code></pre><p>where αs are the weights of dimension (D, A), γs is the covariance matrix of dimension (D, A) and ωs are the mean vectors and is of dimension (D, A). Here, D is input dimension and A is the number of spectral components.</p><p>Spectral Mixture Product Kernel. With enough components A, the SMP kernel can model any product kernel to arbitrary precision, and is flexible even with a small number of components [1]</p><p><code>h</code> is the kernel, which defaults to <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> if not specified.</p><div>\[   κ(x, y) = Πᵢ₌₁ᴷ Σ(αsᵢᵀ .* (h(-(γsᵢᵀ * tᵢ)²) .* cos(ωsᵢᵀ * tᵢ))), tᵢ = xᵢ - yᵢ\]</div><p><strong>References:</strong></p><pre><code class="language-none">[1] GPatt: Fast Multidimensional Pattern Extrapolation with GPs,
    arXiv 1310.5288, 2013, by Andrew Gordon Wilson, Elad Gilboa,
    Arye Nehorai and John P. Cunningham</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/sm.jl#L60-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PeriodicKernel" href="#KernelFunctions.PeriodicKernel"><code>KernelFunctions.PeriodicKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PeriodicKernel(r::AbstractVector)
PeriodicKernel(dims::Int)
PeriodicKernel(T::DataType, dims::Int)</code></pre><p>Periodic Kernel as described in http://www.inference.org.uk/mackay/gpB.pdf eq. 47.</p><pre><code class="language-none">    κ(x,y) = exp( - 0.5 sum_i(sin (π(x_i - y_i))/r_i))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/periodic.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.WienerKernel" href="#KernelFunctions.WienerKernel"><code>KernelFunctions.WienerKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WienerKernel{i}()</code></pre><p>i-times integrated Wiener process kernel function.</p><ul><li>For i=-1, this is just the white noise covariance, see <a href="#KernelFunctions.WhiteKernel"><code>WhiteKernel</code></a>.</li><li>For i= 0, this is the Wiener process covariance,</li><li>For i= 1, this is the integrated Wiener process covariance (velocity),</li><li>For i= 2, this is the twice-integrated Wiener process covariance (accel.),</li><li>For i= 3, this is the thrice-integrated Wiener process covariance,</li></ul><p>where <span>$κᵢ$</span> is given by</p><div>\[    κ₋₁(x, y) =  δ(x, y)
    κ₀(x, y)  =  min(x, y)\]</div><p>and for <span>$i &gt;= 1$</span>,</p><div>\[    κᵢ(x, y) = 1 / aᵢ * min(x, y)^(2i + 1) + bᵢ * min(x, y)^(i + 1) * |x - y| * rᵢ(x, y),\]</div><pre><code class="language-none">with the coefficients ``aᵢ``, ``bᵢ`` and the residual ``rᵢ(x, y)`` defined as follows:</code></pre><div>\[    a₁ = 3, b₁ = 1/2, r₁(x, y) = 1,
    a₂ = 20, b₂ = 1/12, r₂(x, y) = x + y - min(x, y) / 2,
    a₃ = 252, b₃ = 1/720, r₃(x, y) = 5 * max(x, y)² + 2 * x * z + 3 * min(x, y)²
\]</div><p><strong>References:</strong></p><p>See the paper <em>Probabilistic ODE Solvers with Runge-Kutta Means</em> by Schober, Duvenaud and Hennig, NIPS, 2014, for more details.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/basekernels/wiener.jl#L1-L34">source</a></section></article><h2 id="Composite-Kernels"><a class="docs-heading-anchor" href="#Composite-Kernels">Composite Kernels</a><a id="Composite-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Composite-Kernels" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.TransformedKernel" href="#KernelFunctions.TransformedKernel"><code>KernelFunctions.TransformedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TransformedKernel(k::Kernel,t::Transform)</code></pre><p>Return a kernel where inputs are pretransformed by <code>t</code> : <code>k(t(x),t(x&#39;))</code> Can also be called via <a href="#KernelFunctions.transform"><code>transform</code></a> : <code>transform(k, t)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/kernels/transformedkernel.jl#L1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ScaledKernel" href="#KernelFunctions.ScaledKernel"><code>KernelFunctions.ScaledKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ScaledKernel(k::Kernel, σ²::Real)</code></pre><p>Return a kernel premultiplied by the variance <code>σ²</code> : <code>σ² k(x,x&#39;)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/kernels/scaledkernel.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelSum" href="#KernelFunctions.KernelSum"><code>KernelFunctions.KernelSum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KernelSum &lt;: Kernel</code></pre><p>Create a sum of kernels. One can also use the operator <code>+</code>.</p><p>There are various ways in which you create a <code>KernelSum</code>:</p><p>The simplest way to specify a <code>KernelSum</code> would be to use the overloaded <code>+</code> operator. This is  equivalent to creating a <code>KernelSum</code> by specifying the kernels as the arguments to the constructor.  </p><pre><code class="language-julia-repl">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5);

julia&gt; (k = k1 + k2) == KernelSum(k1, k2)
true

julia&gt; kernelmatrix(k1 + k2, X) == kernelmatrix(k1, X) .+ kernelmatrix(k2, X)
true

julia&gt; kernelmatrix(k, X) == kernelmatrix(k1 + k2, X)
true</code></pre><p>You could also specify a <code>KernelSum</code> by providing a <code>Tuple</code> or a <code>Vector</code> of the  kernels to be summed. We suggest you to use a <code>Tuple</code> when you have fewer components   and a <code>Vector</code> when dealing with a large number of components.</p><pre><code class="language-julia-repl">julia&gt; KernelSum((k1, k2)) == k1 + k2
true

julia&gt; KernelSum([k1, k2]) == KernelSum((k1, k2)) == k1 + k2
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/kernels/kernelsum.jl#L1-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelProduct" href="#KernelFunctions.KernelProduct"><code>KernelFunctions.KernelProduct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KernelProduct &lt;: Kernel</code></pre><p>Create a product of kernels. One can also use the overloaded operator <code>*</code>.</p><p>There are various ways in which you create a <code>KernelProduct</code>:</p><p>The simplest way to specify a <code>KernelProduct</code> would be to use the overloaded <code>*</code> operator. This is  equivalent to creating a <code>KernelProduct</code> by specifying the kernels as the arguments to the constructor.  </p><pre><code class="language-julia-repl">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5);

julia&gt; (k = k1 * k2) == KernelProduct(k1, k2)
true

julia&gt; kernelmatrix(k1 * k2, X) == kernelmatrix(k1, X) .* kernelmatrix(k2, X)
true

julia&gt; kernelmatrix(k, X) == kernelmatrix(k1 * k2, X)
true</code></pre><p>You could also specify a <code>KernelProduct</code> by providing a <code>Tuple</code> or a <code>Vector</code> of the  kernels to be multiplied. We suggest you to use a <code>Tuple</code> when you have fewer components   and a <code>Vector</code> when dealing with a large number of components.</p><pre><code class="language-julia-repl">julia&gt; KernelProduct((k1, k2)) == k1 * k2
true

julia&gt; KernelProduct([k1, k2]) == KernelProduct((k1, k2)) == k1 * k2
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/kernels/kernelproduct.jl#L1-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.TensorProduct" href="#KernelFunctions.TensorProduct"><code>KernelFunctions.TensorProduct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TensorProduct(kernels...)</code></pre><p>Create a tensor product kernel from kernels <span>$k_1, \ldots, k_n$</span>, i.e., a kernel <span>$k$</span> that is given by</p><div>\[k(x, y) = \prod_{i=1}^n k_i(x_i, y_i).\]</div><p>The <code>kernels</code> can be specified as individual arguments, a tuple, or an iterable data structure such as an array. Using a tuple or individual arguments guarantees that <code>TensorProduct</code> is concretely typed but might lead to large compilation times if the number of kernels is large.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/kernels/tensorproduct.jl#L1-L14">source</a></section></article><h2 id="Transforms"><a class="docs-heading-anchor" href="#Transforms">Transforms</a><a id="Transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Transforms" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Transform" href="#KernelFunctions.Transform"><code>KernelFunctions.Transform</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type defining a slice-wise transformation on an input matrix</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/KernelFunctions.jl#L46-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.IdentityTransform" href="#KernelFunctions.IdentityTransform"><code>KernelFunctions.IdentityTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">IdentityTransform()</code></pre><p>Return exactly the input</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/transform/transform.jl#L12-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ScaleTransform" href="#KernelFunctions.ScaleTransform"><code>KernelFunctions.ScaleTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ScaleTransform(l::Real)</code></pre><p>Multiply every element of the input by <code>l</code></p><pre><code class="language-none">    l = 2.0
    tr = ScaleTransform(l)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/transform/scaletransform.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ARDTransform" href="#KernelFunctions.ARDTransform"><code>KernelFunctions.ARDTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ARDTransform(v::AbstractVector)
ARDTransform(s::Real, dims::Int)</code></pre><p>Multiply every vector of observation by <code>v</code> element-wise</p><pre><code class="language-none">    v = rand(3)
    tr = ARDTransform(v)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/transform/ardtransform.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.LinearTransform" href="#KernelFunctions.LinearTransform"><code>KernelFunctions.LinearTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinearTransform(A::AbstractMatrix)</code></pre><p>Apply the linear transformation realised by the matrix <code>A</code>.</p><p>The second dimension of <code>A</code> must match the number of features of the target.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = rand(10, 5)

julia&gt; tr = LinearTransform(A)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/transform/lineartransform.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.FunctionTransform" href="#KernelFunctions.FunctionTransform"><code>KernelFunctions.FunctionTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FunctionTransform(f)</code></pre><p>Take a function or object <code>f</code> as an argument which is going to act on each vector individually. Make sure that <code>f</code> is supposed to act on a vector. For example replace <code>f(x)=sin(x)</code> by <code>f(x)=sin.(x)</code></p><pre><code class="language-none">    f(x) = abs.(x)
    tr = FunctionTransform(f)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/transform/functiontransform.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.SelectTransform" href="#KernelFunctions.SelectTransform"><code>KernelFunctions.SelectTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SelectTransform(dims::AbstractVector{Int})</code></pre><p>Select the dimensions <code>dims</code> that the kernel is applied to.</p><pre><code class="language-none">    dims = [1,3,5,6,7]
    tr = SelectTransform(dims)
    X = rand(100,10)
    transform(tr,X,obsdim=2) == X[dims,:]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/transform/selecttransform.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ChainTransform" href="#KernelFunctions.ChainTransform"><code>KernelFunctions.ChainTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ChainTransform(ts::AbstractVector{&lt;:Transform})</code></pre><p>Chain a series of transform, here <code>t1</code> will be called first</p><pre><code class="language-none">    t1 = ScaleTransform()
    t2 = LinearTransform(rand(3,4))
    ct = ChainTransform([t1,t2]) #t1 will be called first
    ct == t2 ∘ t1</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/transform/chaintransform.jl#L1-L11">source</a></section></article><h2 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelmatrix" href="#KernelFunctions.kernelmatrix"><code>KernelFunctions.kernelmatrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kernelmatrix(κ::Kernel, X; obsdim::Int = 2)
kernelmatrix(κ::Kernel, X, Y; obsdim::Int = 2)</code></pre><p>Calculate the kernel matrix of <code>X</code> (and <code>Y</code>) with respect to kernel <code>κ</code>. <code>obsdim = 1</code> means the matrix <code>X</code> (and <code>Y</code>) has size #samples x #dimension <code>obsdim = 2</code> means the matrix <code>X</code> (and <code>Y</code>) has size #dimension x #samples</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/matrix/kernelmatrix.jl#L10-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelmatrix!" href="#KernelFunctions.kernelmatrix!"><code>KernelFunctions.kernelmatrix!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kernelmatrix!(K::AbstractMatrix, κ::Kernel, X; obsdim::Integer = 2)
kernelmatrix!(K::AbstractMatrix, κ::Kernel, X, Y; obsdim::Integer = 2)</code></pre><p>In-place version of <a href="#KernelFunctions.kernelmatrix"><code>kernelmatrix</code></a> where pre-allocated matrix <code>K</code> will be overwritten with the kernel matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/matrix/kernelmatrix.jl#L1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kerneldiagmatrix" href="#KernelFunctions.kerneldiagmatrix"><code>KernelFunctions.kerneldiagmatrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kerneldiagmatrix(κ::Kernel, X; obsdim::Int = 2)</code></pre><p>Calculate the diagonal matrix of <code>X</code> with respect to kernel <code>κ</code> <code>obsdim = 1</code> means the matrix <code>X</code> has size #samples x #dimension <code>obsdim = 2</code> means the matrix <code>X</code> has size #dimension x #samples</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/matrix/kernelmatrix.jl#L27-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kerneldiagmatrix!" href="#KernelFunctions.kerneldiagmatrix!"><code>KernelFunctions.kerneldiagmatrix!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kerneldiagmatrix!(K::AbstractVector, κ::Kernel, X; obsdim::Int = 2)</code></pre><p>In place version of <a href="#KernelFunctions.kerneldiagmatrix"><code>kerneldiagmatrix</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/matrix/kernelmatrix.jl#L20-L24">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>kernelpdmat</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>kernelkronmat</code>. Check Documenter&#39;s build log for details.</p></div></div><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.nystrom" href="#KernelFunctions.nystrom"><code>KernelFunctions.nystrom</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">nystrom(k::Kernel, X::Matrix, S::Vector; obsdim::Int=defaultobs)</code></pre><p>Computes a factorization of Nystrom approximation of the square kernel matrix of data matrix <code>X</code> with respect to kernel <code>k</code>. Returns a <code>NystromFact</code> struct which stores a Nystrom factorization satisfying:</p><div>\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/approximations/nystrom.jl#L62-L71">source</a></section><section><div><pre><code class="language-none">nystrom(k::Kernel, X::Matrix, r::Real; obsdim::Int=defaultobs)</code></pre><p>Computes a factorization of Nystrom approximation of the square kernel matrix of data matrix <code>X</code> with respect to kernel <code>k</code> using a sample ratio of <code>r</code>. Returns a <code>NystromFact</code> struct which stores a Nystrom factorization satisfying:</p><div>\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/approximations/nystrom.jl#L78-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.transform" href="#KernelFunctions.transform"><code>KernelFunctions.transform</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    transform(k::Kernel, t::Transform) (1)
    transform(k::Kernel, ρ::Real) (2)
    transform(k::Kernel, ρ::AbstractVector) (3)</code></pre><p>(1) Create a TransformedKernel with transform <code>t</code> and kernel <code>k</code> (2) Same as (1) with a <code>ScaleTransform</code> with scale <code>ρ</code> (3) Same as (1) with an <code>ARDTransform</code> with scales <code>ρ</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/kernels/transformedkernel.jl#L32-L41">source</a></section></article><h2 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ColVecs" href="#KernelFunctions.ColVecs"><code>KernelFunctions.ColVecs</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ColVecs(X::AbstractMatrix)</code></pre><p>A lightweight wrapper for an <code>AbstractMatrix</code> to make it behave like a vector of vectors. Each vector represents a column of the matrix</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/utils.jl#L23-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.RowVecs" href="#KernelFunctions.RowVecs"><code>KernelFunctions.RowVecs</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RowVecs(X::AbstractMatrix)</code></pre><p>A lightweight wrapper for an <code>AbstractMatrix</code> to make it behave like a vector of vectors. Each vector represents a row of the matrix</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/utils.jl#L53-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.NystromFact" href="#KernelFunctions.NystromFact"><code>KernelFunctions.NystromFact</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NystromFact</code></pre><p>Type for storing a Nystrom factorization. The factorization contains two fields: <code>W</code> and <code>C</code>, two matrices satisfying:</p><div>\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/0df9e8352d7d9f034f75de4d3639c0bb3b96c714/src/approximations/nystrom.jl#L43-L51">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#KernelFunctions.ARDTransform"><code>KernelFunctions.ARDTransform</code></a></li><li><a href="#KernelFunctions.ChainTransform"><code>KernelFunctions.ChainTransform</code></a></li><li><a href="#KernelFunctions.ColVecs"><code>KernelFunctions.ColVecs</code></a></li><li><a href="#KernelFunctions.ConstantKernel"><code>KernelFunctions.ConstantKernel</code></a></li><li><a href="#KernelFunctions.CosineKernel"><code>KernelFunctions.CosineKernel</code></a></li><li><a href="#KernelFunctions.ExponentialKernel"><code>KernelFunctions.ExponentialKernel</code></a></li><li><a href="#KernelFunctions.ExponentiatedKernel"><code>KernelFunctions.ExponentiatedKernel</code></a></li><li><a href="#KernelFunctions.EyeKernel"><code>KernelFunctions.EyeKernel</code></a></li><li><a href="#KernelFunctions.FBMKernel"><code>KernelFunctions.FBMKernel</code></a></li><li><a href="#KernelFunctions.FunctionTransform"><code>KernelFunctions.FunctionTransform</code></a></li><li><a href="#KernelFunctions.GaborKernel"><code>KernelFunctions.GaborKernel</code></a></li><li><a href="#KernelFunctions.GammaExponentialKernel"><code>KernelFunctions.GammaExponentialKernel</code></a></li><li><a href="#KernelFunctions.GammaRationalQuadraticKernel"><code>KernelFunctions.GammaRationalQuadraticKernel</code></a></li><li><a href="#KernelFunctions.IdentityTransform"><code>KernelFunctions.IdentityTransform</code></a></li><li><a href="#KernelFunctions.KernelProduct"><code>KernelFunctions.KernelProduct</code></a></li><li><a href="#KernelFunctions.KernelSum"><code>KernelFunctions.KernelSum</code></a></li><li><a href="#KernelFunctions.LinearKernel"><code>KernelFunctions.LinearKernel</code></a></li><li><a href="#KernelFunctions.LinearTransform"><code>KernelFunctions.LinearTransform</code></a></li><li><a href="#KernelFunctions.MahalanobisKernel"><code>KernelFunctions.MahalanobisKernel</code></a></li><li><a href="#KernelFunctions.Matern32Kernel"><code>KernelFunctions.Matern32Kernel</code></a></li><li><a href="#KernelFunctions.Matern52Kernel"><code>KernelFunctions.Matern52Kernel</code></a></li><li><a href="#KernelFunctions.MaternKernel"><code>KernelFunctions.MaternKernel</code></a></li><li><a href="#KernelFunctions.NeuralNetworkKernel"><code>KernelFunctions.NeuralNetworkKernel</code></a></li><li><a href="#KernelFunctions.NystromFact"><code>KernelFunctions.NystromFact</code></a></li><li><a href="#KernelFunctions.PeriodicKernel"><code>KernelFunctions.PeriodicKernel</code></a></li><li><a href="#KernelFunctions.PiecewisePolynomialKernel"><code>KernelFunctions.PiecewisePolynomialKernel</code></a></li><li><a href="#KernelFunctions.PolynomialKernel"><code>KernelFunctions.PolynomialKernel</code></a></li><li><a href="#KernelFunctions.RationalQuadraticKernel"><code>KernelFunctions.RationalQuadraticKernel</code></a></li><li><a href="#KernelFunctions.RowVecs"><code>KernelFunctions.RowVecs</code></a></li><li><a href="#KernelFunctions.ScaleTransform"><code>KernelFunctions.ScaleTransform</code></a></li><li><a href="#KernelFunctions.ScaledKernel"><code>KernelFunctions.ScaledKernel</code></a></li><li><a href="#KernelFunctions.SelectTransform"><code>KernelFunctions.SelectTransform</code></a></li><li><a href="#KernelFunctions.SqExponentialKernel"><code>KernelFunctions.SqExponentialKernel</code></a></li><li><a href="#KernelFunctions.TensorProduct"><code>KernelFunctions.TensorProduct</code></a></li><li><a href="#KernelFunctions.Transform"><code>KernelFunctions.Transform</code></a></li><li><a href="#KernelFunctions.TransformedKernel"><code>KernelFunctions.TransformedKernel</code></a></li><li><a href="#KernelFunctions.WhiteKernel"><code>KernelFunctions.WhiteKernel</code></a></li><li><a href="#KernelFunctions.WienerKernel"><code>KernelFunctions.WienerKernel</code></a></li><li><a href="#KernelFunctions.ZeroKernel"><code>KernelFunctions.ZeroKernel</code></a></li><li><a href="#KernelFunctions.kerneldiagmatrix"><code>KernelFunctions.kerneldiagmatrix</code></a></li><li><a href="#KernelFunctions.kerneldiagmatrix!"><code>KernelFunctions.kerneldiagmatrix!</code></a></li><li><a href="#KernelFunctions.kernelmatrix"><code>KernelFunctions.kernelmatrix</code></a></li><li><a href="#KernelFunctions.kernelmatrix!"><code>KernelFunctions.kernelmatrix!</code></a></li><li><a href="#KernelFunctions.nystrom"><code>KernelFunctions.nystrom</code></a></li><li><a href="#KernelFunctions.spectral_mixture_kernel"><code>KernelFunctions.spectral_mixture_kernel</code></a></li><li><a href="#KernelFunctions.spectral_mixture_product_kernel"><code>KernelFunctions.spectral_mixture_product_kernel</code></a></li><li><a href="#KernelFunctions.transform"><code>KernelFunctions.transform</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../create_kernel/">« Custom Kernels</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 7 August 2020 20:40">Friday 7 August 2020</span>. Using Julia version 1.5.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
