<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · KernelFunctions.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">KernelFunctions.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../userguide/">User guide</a></li><li><a class="tocitem" href="../kernels/">Kernel Functions</a></li><li><a class="tocitem" href="../transform/">Input Transforms</a></li><li><a class="tocitem" href="../metrics/">Metrics</a></li><li><a class="tocitem" href="../create_kernel/">Custom Kernels</a></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li><a class="tocitem" href="#Functions"><span>Functions</span></a></li><li><a class="tocitem" href="#Input-Types"><span>Input Types</span></a></li><li><a class="tocitem" href="#Generic-Utilities"><span>Generic Utilities</span></a></li><li><a class="tocitem" href="#Conditional-Utilities"><span>Conditional Utilities</span></a></li></ul></li><li><a class="tocitem" href="../design/">Design</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/gaussian-process-priors/">Gaussian process prior samples</a></li><li><a class="tocitem" href="../examples/kernel-ridge-regression/">Kernel Ridge Regression</a></li><li><a class="tocitem" href="../examples/support-vector-machine/">Support Vector Machine</a></li><li><a class="tocitem" href="../examples/train-kernel-parameters/">Train Kernel Parameters</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Library"><a class="docs-heading-anchor" href="#API-Library">API Library</a><a id="API-Library-1"></a><a class="docs-heading-anchor-permalink" href="#API-Library" title="Permalink"></a></h1><h2 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h2><p>The KernelFunctions API comprises the following four functions.</p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelmatrix" href="#KernelFunctions.kernelmatrix"><code>KernelFunctions.kernelmatrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kernelmatrix(κ::Kernel, x::AbstractVector)</code></pre><p>Compute the kernel <code>κ</code> for each pair of inputs in <code>x</code>. Returns a matrix of size <code>(length(x), length(x))</code> satisfying <code>kernelmatrix(κ, x)[p, q] == κ(x[p], x[q])</code>.</p><pre><code class="nohighlight hljs">kernelmatrix(κ::Kernel, x::AbstractVector, y::AbstractVector)</code></pre><p>Compute the kernel <code>κ</code> for each pair of inputs in <code>x</code> and <code>y</code>. Returns a matrix of size <code>(length(x), length(y))</code> satisfying <code>kernelmatrix(κ, x, y)[p, q] == κ(x[p], y[q])</code>.</p><pre><code class="nohighlight hljs">kernelmatrix(κ::Kernel, X::AbstractMatrix; obsdim)
kernelmatrix(κ::Kernel, X::AbstractMatrix, Y::AbstractMatrix; obsdim)</code></pre><p>If <code>obsdim=1</code>, equivalent to <code>kernelmatrix(κ, RowVecs(X))</code> and <code>kernelmatrix(κ, RowVecs(X), RowVecs(Y))</code>, respectively. If <code>obsdim=2</code>, equivalent to <code>kernelmatrix(κ, ColVecs(X))</code> and <code>kernelmatrix(κ, ColVecs(X), ColVecs(Y))</code>, respectively.</p><p>See also: <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a>, <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelmatrix.jl#L26-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelmatrix!" href="#KernelFunctions.kernelmatrix!"><code>KernelFunctions.kernelmatrix!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kernelmatrix!(K::AbstractMatrix, κ::Kernel, x::AbstractVector)
kernelmatrix!(K::AbstractMatrix, κ::Kernel, x::AbstractVector, y::AbstractVector)</code></pre><p>In-place version of <a href="#KernelFunctions.kernelmatrix"><code>kernelmatrix</code></a> where pre-allocated matrix <code>K</code> will be overwritten with the kernel matrix.</p><pre><code class="nohighlight hljs">kernelmatrix!(K::AbstractMatrix, κ::Kernel, X::AbstractMatrix; obsdim)
kernelmatrix!(
    K::AbstractMatrix,
    κ::Kernel,
    X::AbstractMatrix,
    Y::AbstractMatrix;
    obsdim,
)</code></pre><p>If <code>obsdim=1</code>, equivalent to <code>kernelmatrix!(K, κ, RowVecs(X))</code> and <code>kernelmatrix(K, κ, RowVecs(X), RowVecs(Y))</code>, respectively. If <code>obsdim=2</code>, equivalent to <code>kernelmatrix!(K, κ, ColVecs(X))</code> and <code>kernelmatrix(K, κ, ColVecs(X), ColVecs(Y))</code>, respectively.</p><p>See also: <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a>, <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelmatrix.jl#L1-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelmatrix_diag" href="#KernelFunctions.kernelmatrix_diag"><code>KernelFunctions.kernelmatrix_diag</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kernelmatrix_diag(κ::Kernel, x::AbstractVector)</code></pre><p>Compute the diagonal of <code>kernelmatrix(κ, x)</code> efficiently.</p><pre><code class="nohighlight hljs">kernelmatrix_diag(κ::Kernel, x::AbstractVector, y::AbstractVector)</code></pre><p>Compute the diagonal of <code>kernelmatrix(κ, x, y)</code> efficiently. Requires that <code>x</code> and <code>y</code> are the same length.</p><pre><code class="nohighlight hljs">kernelmatrix_diag(κ::Kernel, X::AbstractMatrix; obsdim)
kernelmatrix_diag(κ::Kernel, X::AbstractMatrix, Y::AbstractMatrix; obsdim)</code></pre><p>If <code>obsdim=1</code>, equivalent to <code>kernelmatrix_diag(κ, RowVecs(X))</code> and <code>kernelmatrix_diag(κ, RowVecs(X), RowVecs(Y))</code>, respectively. If <code>obsdim=2</code>, equivalent to <code>kernelmatrix_diag(κ, ColVecs(X))</code> and <code>kernelmatrix_diag(κ, ColVecs(X), ColVecs(Y))</code>, respectively.</p><p>See also: <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a>, <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelmatrix.jl#L75-L94">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelmatrix_diag!" href="#KernelFunctions.kernelmatrix_diag!"><code>KernelFunctions.kernelmatrix_diag!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kernelmatrix_diag!(K::AbstractVector, κ::Kernel, x::AbstractVector)
kernelmatrix_diag!(K::AbstractVector, κ::Kernel, x::AbstractVector, y::AbstractVector)</code></pre><p>In place version of <a href="#KernelFunctions.kernelmatrix_diag"><code>kernelmatrix_diag</code></a>.</p><pre><code class="nohighlight hljs">kernelmatrix_diag!(K::AbstractVector, κ::Kernel, X::AbstractMatrix; obsdim)
kernelmatrix_diag!(
    K::AbstractVector,
    κ::Kernel,
    X::AbstractMatrix,
    Y::AbstractMatrix;
    obsdim
)</code></pre><p>If <code>obsdim=1</code>, equivalent to <code>kernelmatrix_diag!(K, κ, RowVecs(X))</code> and <code>kernelmatrix_diag!(K, κ, RowVecs(X), RowVecs(Y))</code>, respectively. If <code>obsdim=2</code>, equivalent to <code>kernelmatrix_diag!(K, κ, ColVecs(X))</code> and <code>kernelmatrix_diag!(K, κ, ColVecs(X), ColVecs(Y))</code>, respectively.</p><p>See also: <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a>, <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelmatrix.jl#L51-L72">source</a></section></article><h2 id="Input-Types"><a class="docs-heading-anchor" href="#Input-Types">Input Types</a><a id="Input-Types-1"></a><a class="docs-heading-anchor-permalink" href="#Input-Types" title="Permalink"></a></h2><p>The above API operates on collections of inputs. All collections of inputs in KernelFunctions.jl are represented as <code>AbstractVector</code>s. To understand this choice, please see the <a href="../design/#why_abstract_vectors">design notes on collections of inputs</a>. The length of any such <code>AbstractVector</code> is equal to the number of inputs in the collection. For example, this means that</p><pre><code class="language-julia hljs">size(kernelmatrix(k, x)) == (length(x), length(x))</code></pre><p>is always true, for some <code>Kernel</code> <code>k</code>, and <code>AbstractVector</code> <code>x</code>.</p><h3 id="Univariate-Inputs"><a class="docs-heading-anchor" href="#Univariate-Inputs">Univariate Inputs</a><a id="Univariate-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#Univariate-Inputs" title="Permalink"></a></h3><p>If each input to your kernel is <code>Real</code>-valued, then any <code>AbstractVector{&lt;:Real}</code> is a valid representation for a collection of inputs. More generally, it&#39;s completely fine to represent a collection of inputs of type <code>T</code> as, for example, a <code>Vector{T}</code>. However, this may not be the most efficient way to represent collection of inputs. See <a href="#Vector-Valued-Inputs">Vector-Valued Inputs</a> for an example.</p><h3 id="Vector-Valued-Inputs"><a class="docs-heading-anchor" href="#Vector-Valued-Inputs">Vector-Valued Inputs</a><a id="Vector-Valued-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#Vector-Valued-Inputs" title="Permalink"></a></h3><p>We recommend that collections of vector-valued inputs are stored in an <code>AbstractMatrix{&lt;:Real}</code> when possible, and wrapped inside a <code>ColVecs</code> or <code>RowVecs</code> to make their interpretation clear:</p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ColVecs" href="#KernelFunctions.ColVecs"><code>KernelFunctions.ColVecs</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ColVecs(X::AbstractMatrix)</code></pre><p>A lightweight wrapper for an <code>AbstractMatrix</code> which interprets it as a vector-of-vectors, in which each <em>column</em> of <code>X</code> represents a single vector.</p><p>That is, by writing <code>x = ColVecs(X)</code>, you are saying &quot;<code>x</code> is a vector-of-vectors, each of which has length <code>size(X, 1)</code>. The total number of vectors is <code>size(X, 2)</code>.&quot;</p><p>Phrased differently, <code>ColVecs(X)</code> says that <code>X</code> should be interpreted as a vector of horizontally-concatenated column-vectors, hence the name <code>ColVecs</code>.</p><pre><code class="language-julia-repl hljs">julia&gt; X = randn(2, 5);

julia&gt; x = ColVecs(X);

julia&gt; length(x) == 5
true

julia&gt; X[:, 3] == x[3]
true</code></pre><p><code>ColVecs</code> is related to <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a> via transposition:</p><pre><code class="language-julia-repl hljs">julia&gt; X = randn(2, 5);

julia&gt; ColVecs(X) == RowVecs(X&#39;)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/utils.jl#L49-L80">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.RowVecs" href="#KernelFunctions.RowVecs"><code>KernelFunctions.RowVecs</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RowVecs(X::AbstractMatrix)</code></pre><p>A lightweight wrapper for an <code>AbstractMatrix</code> which interprets it as a vector-of-vectors, in which each <em>row</em> of <code>X</code> represents a single vector.</p><p>That is, by writing <code>x = RowVecs(X)</code>, you are saying &quot;<code>x</code> is a vector-of-vectors, each of which has length <code>size(X, 2)</code>. The total number of vectors is <code>size(X, 1)</code>.&quot;</p><p>Phrased differently, <code>RowVecs(X)</code> says that <code>X</code> should be interpreted as a vector of vertically-concatenated row-vectors, hence the name <code>RowVecs</code>.</p><p>Internally, the data continues to be represented as an <code>AbstractMatrix</code>, so using this type does not introduce any kind of performance penalty.</p><pre><code class="language-julia-repl hljs">julia&gt; X = randn(5, 2);

julia&gt; x = RowVecs(X);

julia&gt; length(x) == 5
true

julia&gt; X[3, :] == x[3]
true</code></pre><p><code>RowVecs</code> is related to <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a> via transposition:</p><pre><code class="language-julia-repl hljs">julia&gt; X = randn(5, 2);

julia&gt; RowVecs(X) == ColVecs(X&#39;)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/utils.jl#L117-L151">source</a></section></article><p>These types are specialised upon to ensure good performance e.g. when computing Euclidean distances between pairs of elements. The benefit of using this representation, rather than using a <code>Vector{Vector{&lt;:Real}}</code>, is that optimised matrix-matrix multiplication functionality can be utilised when computing pairwise distances between inputs, which are needed for <code>kernelmatrix</code> computation.</p><h3 id="Inputs-for-Multiple-Outputs"><a class="docs-heading-anchor" href="#Inputs-for-Multiple-Outputs">Inputs for Multiple Outputs</a><a id="Inputs-for-Multiple-Outputs-1"></a><a class="docs-heading-anchor-permalink" href="#Inputs-for-Multiple-Outputs" title="Permalink"></a></h3><p>KernelFunctions.jl views multi-output GPs as GPs on an extended input domain. For an explanation of this design choice, see <a href="../design/#inputs_for_multiple_outputs">the design notes on multi-output GPs</a>.</p><p>An input to a multi-output <code>Kernel</code> should be a <code>Tuple{T, Int}</code>, whose first element specifies a location in the domain of the multi-output GP, and whose second element specifies which output the inputs corresponds to. The type of collections of inputs for multi-output GPs is therefore <code>AbstractVector{&lt;:Tuple{T, Int}}</code>.</p><p>KernelFunctions.jl provides the following helper functions to reduce the cognitive load associated with working with multi-output kernels by dealing with transforming data from the formats in which it is commonly found into the format required by KernelFunctions. The intention is that users can pass their data to these functions, and use the returned values throughout their code, without having to worry further about correctly formatting their data for KernelFunctions&#39; sake:</p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.prepare_isotopic_multi_output_data-Tuple{AbstractVector, ColVecs}" href="#KernelFunctions.prepare_isotopic_multi_output_data-Tuple{AbstractVector, ColVecs}"><code>KernelFunctions.prepare_isotopic_multi_output_data</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">prepare_isotopic_multi_output_data(x::AbstractVector, y::ColVecs)</code></pre><p>Utility functionality to convert a collection of <code>N = length(x)</code> inputs <code>x</code>, and a vector-of-vectors <code>y</code> (efficiently represented by a <code>ColVecs</code>) into a format suitable for use with multi-output kernels.</p><p><code>y[n]</code> is the vector-valued output corresponding to the input <code>x[n]</code>. Consequently, it is necessary that <code>length(x) == length(y)</code>.</p><p>For example, if outputs are initially stored in a <code>num_outputs × N</code> matrix:</p><pre><code class="language-julia hljs">julia&gt; x = [1.0, 2.0, 3.0];

julia&gt; Y = [1.1 2.1 3.1; 1.2 2.2 3.2]
2×3 Matrix{Float64}:
 1.1  2.1  3.1
 1.2  2.2  3.2

julia&gt; inputs, outputs = prepare_isotopic_multi_output_data(x, ColVecs(Y));

julia&gt; inputs
6-element KernelFunctions.MOInputIsotopicByFeatures{Float64, Vector{Float64}, Int64}:
 (1.0, 1)
 (1.0, 2)
 (2.0, 1)
 (2.0, 2)
 (3.0, 1)
 (3.0, 2)

julia&gt; outputs
6-element Vector{Float64}:
 1.1
 1.2
 2.1
 2.2
 3.1
 3.2</code></pre><p>See also <a href="#KernelFunctions.prepare_heterotopic_multi_output_data"><code>prepare_heterotopic_multi_output_data</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/mokernels/moinput.jl#L119-L160">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.prepare_isotopic_multi_output_data-Tuple{AbstractVector, RowVecs}" href="#KernelFunctions.prepare_isotopic_multi_output_data-Tuple{AbstractVector, RowVecs}"><code>KernelFunctions.prepare_isotopic_multi_output_data</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">prepare_isotopic_multi_output_data(x::AbstractVector, y::RowVecs)</code></pre><p>Utility functionality to convert a collection of <code>N = length(x)</code> inputs <code>x</code> and output vectors <code>y</code> (efficiently represented by a <code>RowVecs</code>) into a format suitable for use with multi-output kernels.</p><p><code>y[n]</code> is the vector-valued output corresponding to the input <code>x[n]</code>. Consequently, it is necessary that <code>length(x) == length(y)</code>.</p><p>For example, if outputs are initial stored in an <code>N × num_outputs</code> matrix:</p><pre><code class="language-julia-repl hljs">julia&gt; x = [1.0, 2.0, 3.0];

julia&gt; Y = [1.1 1.2; 2.1 2.2; 3.1 3.2]
3×2 Matrix{Float64}:
 1.1  1.2
 2.1  2.2
 3.1  3.2

julia&gt; inputs, outputs = prepare_isotopic_multi_output_data(x, RowVecs(Y));

julia&gt; inputs
6-element KernelFunctions.MOInputIsotopicByOutputs{Float64, Vector{Float64}, Int64}:
 (1.0, 1)
 (2.0, 1)
 (3.0, 1)
 (1.0, 2)
 (2.0, 2)
 (3.0, 2)

julia&gt; outputs
6-element Vector{Float64}:
 1.1
 2.1
 3.1
 1.2
 2.2
 3.2</code></pre><p>See also <a href="#KernelFunctions.prepare_heterotopic_multi_output_data"><code>prepare_heterotopic_multi_output_data</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/mokernels/moinput.jl#L166-L208">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.prepare_heterotopic_multi_output_data" href="#KernelFunctions.prepare_heterotopic_multi_output_data"><code>KernelFunctions.prepare_heterotopic_multi_output_data</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">prepare_heterotopic_multi_output_data(
    x::AbstractVector, y::AbstractVector{&lt;:Real}, output_indices::AbstractVector{Int},
)</code></pre><p>Utility functionality to convert a collection of inputs <code>x</code>, observations <code>y</code>, and <code>output_indices</code> into a format suitable for use with multi-output kernels. Handles the situation in which only one (or a subset) of outputs are observed at each feature. Ensures that all arguments are compatible with one another, and returns a vector of inputs and a vector of outputs.</p><p><code>y[n]</code> should be the observed value associated with output <code>output_indices[n]</code> at feature <code>x[n]</code>.</p><pre><code class="language-julia-repl hljs">julia&gt; x = [1.0, 2.0, 3.0];

julia&gt; y = [-1.0, 0.0, 1.0];

julia&gt; output_indices = [3, 2, 1];

julia&gt; inputs, outputs = prepare_heterotopic_multi_output_data(x, y, output_indices);

julia&gt; inputs
3-element Vector{Tuple{Float64, Int64}}:
 (1.0, 3)
 (2.0, 2)
 (3.0, 1)

julia&gt; outputs
3-element Vector{Float64}:
 -1.0
  0.0
  1.0</code></pre><p>See also <a href="#KernelFunctions.prepare_isotopic_multi_output_data-Tuple{AbstractVector, ColVecs}"><code>prepare_isotopic_multi_output_data</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/mokernels/moinput.jl#L214-L252">source</a></section></article><p>The input types returned by <code>prepare_isotopic_multi_output_data</code> can also be constructed manually:</p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.MOInput" href="#KernelFunctions.MOInput"><code>KernelFunctions.MOInput</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MOInput(x::AbstractVector, out_dim::Integer)</code></pre><p>A data type to accommodate modelling multi-dimensional output data. <code>MOInput(x, out_dim)</code> has length <code>length(x) * out_dim</code>.</p><pre><code class="language-julia-repl hljs">julia&gt; x = [1, 2, 3];

julia&gt; MOInput(x, 2)
6-element KernelFunctions.MOInputIsotopicByOutputs{Int64, Vector{Int64}, Int64}:
 (1, 1)
 (2, 1)
 (3, 1)
 (1, 2)
 (2, 2)
 (3, 2)</code></pre><p>As shown above, an <code>MOInput</code> represents a vector of tuples. The first <code>length(x)</code> elements represent the inputs for the first output, the second <code>length(x)</code> elements represent the inputs for the second output, etc. See <a href="#Inputs-for-Multiple-Outputs">Inputs for Multiple Outputs</a> in the docs for more info.</p><p><code>MOInput</code> will be deprecated in version 0.11 in favour of <code>MOInputIsotopicByOutputs</code>, and removed in version 0.12.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/mokernels/moinput.jl#L91-L116">source</a></section></article><p>As with <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a> and <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a> for vector-valued input spaces, this type enables specialised implementations of e.g. <a href="#KernelFunctions.kernelmatrix"><code>kernelmatrix</code></a> for <a href="#KernelFunctions.MOInput"><code>MOInput</code></a>s in some situations.</p><p>To find out more about the background, read this <a href="https://arxiv.org/pdf/1106.6251.pdf">review of kernels for vector-valued functions</a>.</p><h2 id="Generic-Utilities"><a class="docs-heading-anchor" href="#Generic-Utilities">Generic Utilities</a><a id="Generic-Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Generic-Utilities" title="Permalink"></a></h2><p>KernelFunctions also provides miscellaneous utility functions.</p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.nystrom" href="#KernelFunctions.nystrom"><code>KernelFunctions.nystrom</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">nystrom(k::Kernel, X::AbstractVector, S::AbstractVector{&lt;:Integer})</code></pre><p>Compute a factorization of a Nystrom approximation of the square kernel matrix of data vector <code>X</code> with respect to kernel <code>k</code>, using indices <code>S</code>. Returns a <code>NystromFact</code> struct which stores a Nystrom factorization satisfying:</p><p class="math-container">\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/approximations/nystrom.jl#L72-L81">source</a></section><section><div><pre><code class="nohighlight hljs">nystrom(k::Kernel, X::AbstractVector, r::Real)</code></pre><p>Compute a factorization of a Nystrom approximation of the square kernel matrix of data vector <code>X</code> with respect to kernel <code>k</code> using a sample ratio of <code>r</code>. Returns a <code>NystromFact</code> struct which stores a Nystrom factorization satisfying:</p><p class="math-container">\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/approximations/nystrom.jl#L88-L97">source</a></section><section><div><pre><code class="nohighlight hljs">nystrom(k::Kernel, X::AbstractMatrix, S::AbstractVector{&lt;:Integer}; obsdim)</code></pre><p>If <code>obsdim=1</code>, equivalent to <code>nystrom(k, RowVecs(X), S)</code>. If <code>obsdim=2</code>, equivalent to <code>nystrom(k, ColVecs(X), S)</code>.</p><p>See also: <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a>, <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/approximations/nystrom.jl#L103-L110">source</a></section><section><div><pre><code class="nohighlight hljs">nystrom(k::Kernel, X::AbstractMatrix, r::Real; obsdim)</code></pre><p>If <code>obsdim=1</code>, equivalent to <code>nystrom(k, RowVecs(X), r)</code>. If <code>obsdim=2</code>, equivalent to <code>nystrom(k, ColVecs(X), r)</code>.</p><p>See also: <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a>, <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/approximations/nystrom.jl#L120-L127">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.NystromFact" href="#KernelFunctions.NystromFact"><code>KernelFunctions.NystromFact</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NystromFact</code></pre><p>Type for storing a Nystrom factorization. The factorization contains two fields: <code>W</code> and <code>C</code>, two matrices satisfying:</p><p class="math-container">\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/approximations/nystrom.jl#L53-L61">source</a></section></article><h2 id="Conditional-Utilities"><a class="docs-heading-anchor" href="#Conditional-Utilities">Conditional Utilities</a><a id="Conditional-Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-Utilities" title="Permalink"></a></h2><p>To keep the dependencies of KernelFunctions lean, some functionality is only available if specific other packages are explicitly loaded (<code>using</code>).</p><h3 id="Kronecker.jl"><a class="docs-heading-anchor" href="#Kronecker.jl">Kronecker.jl</a><a id="Kronecker.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Kronecker.jl" title="Permalink"></a></h3><p><a href="https://github.com/MichielStock/Kronecker.jl"><em>https://github.com/MichielStock/Kronecker.jl</em></a></p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kronecker_kernelmatrix" href="#KernelFunctions.kronecker_kernelmatrix"><code>KernelFunctions.kronecker_kernelmatrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kronecker_kernelmatrix(
    k::Union{IndependentMOKernel,IntrinsicCoregionMOKernel}, x::MOI, y::MOI
) where {MOI&lt;:IsotopicMOInputsUnion}</code></pre><p>Requires Kronecker.jl: Computes the <code>kernelmatrix</code> for the <code>IndependentMOKernel</code> and the <code>IntrinsicCoregionMOKernel</code>, but returns a lazy kronecker product. This object can be very efficiently inverted or decomposed. See also <a href="#KernelFunctions.kernelmatrix"><code>kernelmatrix</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelkroneckermat.jl#L73-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelkronmat" href="#KernelFunctions.kernelkronmat"><code>KernelFunctions.kernelkronmat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kernelkronmat(κ::Kernel, X::AbstractVector{&lt;:Real}, dims::Int) -&gt; KroneckerPower</code></pre><p>Return a <code>KroneckerPower</code> matrix on the <code>D</code>-dimensional input grid constructed by <span>$\otimes_{i=1}^D X$</span>, where <code>D</code> is given by <code>dims</code>.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Requires <code>Kronecker.jl</code> and for <code>iskroncompatible(κ)</code> to return <code>true</code>.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelkroneckermat.jl#L9-L18">source</a></section><section><div><pre><code class="nohighlight hljs">kernelkronmat(κ::Kernel, X::AbstractVector{&lt;:AbstractVector}) -&gt; KroneckerProduct</code></pre><p>Returns a <code>KroneckerProduct</code> matrix on the grid built with the collection of vectors <span>$\{X_i\}_{i=1}^D$</span>: <span>$\otimes_{i=1}^D X_i$</span>.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Requires <code>Kronecker.jl</code> and for <code>iskroncompatible(κ)</code> to return <code>true</code>.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelkroneckermat.jl#L25-L34">source</a></section></article><h3 id="PDMats.jl"><a class="docs-heading-anchor" href="#PDMats.jl">PDMats.jl</a><a id="PDMats.jl-1"></a><a class="docs-heading-anchor-permalink" href="#PDMats.jl" title="Permalink"></a></h3><p><a href="https://github.com/JuliaStats/PDMats.jl"><em>https://github.com/JuliaStats/PDMats.jl</em></a></p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelpdmat" href="#KernelFunctions.kernelpdmat"><code>KernelFunctions.kernelpdmat</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">kernelpdmat(k::Kernel, X::AbstractVector)</code></pre><p>Compute a positive-definite matrix in the form of a <code>PDMat</code> matrix (see <a href="https://github.com/JuliaStats/PDMats.jl">PDMats.jl</a>), with the Cholesky decomposition precomputed. The algorithm adds a diagonal &quot;nugget&quot; term to the kernel matrix which is increased until positive definiteness is achieved. The algorithm gives up with an error if the nugget becomes larger than 1% of the largest value in the kernel matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelpdmat.jl#L5-L12">source</a></section><section><div><pre><code class="nohighlight hljs">kernelpdmat(k::Kernel, X::AbstractMatrix; obsdim)</code></pre><p>If <code>obsdim=1</code>, equivalent to <code>kernelpdmat(k, RowVecs(X))</code>. If <code>obsdim=2</code>, equivalent to <code>kernelpdmat(k, ColVecs(X))</code>.</p><p>See also: <a href="#KernelFunctions.ColVecs"><code>ColVecs</code></a>, <a href="#KernelFunctions.RowVecs"><code>RowVecs</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/c3fa129fd1731556e172c8764117bbd296a056ec/src/matrix/kernelpdmat.jl#L30-L37">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../create_kernel/">« Custom Kernels</a><a class="docs-footer-nextpage" href="../design/">Design »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Tuesday 12 August 2025 09:25">Tuesday 12 August 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
