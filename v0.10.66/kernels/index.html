<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Kernel Functions · KernelFunctions.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">KernelFunctions.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../userguide/">User guide</a></li><li class="is-active"><a class="tocitem" href>Kernel Functions</a><ul class="internal"><li><a class="tocitem" href="#base_kernels"><span>Base Kernels</span></a></li><li><a class="tocitem" href="#Composite-Kernels"><span>Composite Kernels</span></a></li><li><a class="tocitem" href="#Multi-output-Kernels"><span>Multi-output Kernels</span></a></li></ul></li><li><a class="tocitem" href="../transform/">Input Transforms</a></li><li><a class="tocitem" href="../metrics/">Metrics</a></li><li><a class="tocitem" href="../create_kernel/">Custom Kernels</a></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../design/">Design</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/gaussian-process-priors/">Gaussian process prior samples</a></li><li><a class="tocitem" href="../examples/kernel-ridge-regression/">Kernel Ridge Regression</a></li><li><a class="tocitem" href="../examples/support-vector-machine/">Support Vector Machine</a></li><li><a class="tocitem" href="../examples/train-kernel-parameters/">Train Kernel Parameters</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Kernel Functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Kernel Functions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/master/docs/src/kernels.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Kernel-Functions"><a class="docs-heading-anchor" href="#Kernel-Functions">Kernel Functions</a><a id="Kernel-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-Functions" title="Permalink"></a></h1><h2 id="base_kernels"><a class="docs-heading-anchor" href="#base_kernels">Base Kernels</a><a id="base_kernels-1"></a><a class="docs-heading-anchor-permalink" href="#base_kernels" title="Permalink"></a></h2><p>These are the basic kernels without any transformation of the data. They are the building blocks of KernelFunctions.</p><h3 id="Constant-Kernels"><a class="docs-heading-anchor" href="#Constant-Kernels">Constant Kernels</a><a id="Constant-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Constant-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ZeroKernel" href="#KernelFunctions.ZeroKernel"><code>KernelFunctions.ZeroKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ZeroKernel()</code></pre><p>Zero kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span>, the zero kernel is defined as</p><p class="math-container">\[k(x, x&#39;) = 0.\]</p><p>The output type depends on <span>$x$</span> and <span>$x&#39;$</span>.</p><p>See also: <a href="#KernelFunctions.ConstantKernel"><code>ConstantKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/constant.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ConstantKernel" href="#KernelFunctions.ConstantKernel"><code>KernelFunctions.ConstantKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConstantKernel(; c::Real=1.0)</code></pre><p>Kernel of constant value <code>c</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span>, the kernel of constant value <span>$c \geq 0$</span> is defined as</p><p class="math-container">\[k(x, x&#39;) = c.\]</p><p>See also: <a href="#KernelFunctions.ZeroKernel"><code>ZeroKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/constant.jl#L84-L97">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.WhiteKernel" href="#KernelFunctions.WhiteKernel"><code>KernelFunctions.WhiteKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WhiteKernel()</code></pre><p>White noise kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span>, the white noise kernel is defined as</p><p class="math-container">\[k(x, x&#39;) = \delta(x, x&#39;).\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/constant.jl#L57-L68">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.EyeKernel" href="#KernelFunctions.EyeKernel"><code>KernelFunctions.EyeKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">EyeKernel()</code></pre><p>Alias of <a href="#KernelFunctions.WhiteKernel"><code>WhiteKernel</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/constant.jl#L71-L75">source</a></section></article><h3 id="Cosine-Kernel"><a class="docs-heading-anchor" href="#Cosine-Kernel">Cosine Kernel</a><a id="Cosine-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Cosine-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.CosineKernel" href="#KernelFunctions.CosineKernel"><code>KernelFunctions.CosineKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CosineKernel(; metric=Euclidean())</code></pre><p>Cosine kernel with respect to the <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the cosine kernel is defined as</p><p class="math-container">\[k(x, x&#39;) = \cos(\pi d(x, x&#39;)).\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/cosine.jl#L1-L13">source</a></section></article><h3 id="Exponential-Kernels"><a class="docs-heading-anchor" href="#Exponential-Kernels">Exponential Kernels</a><a id="Exponential-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Exponential-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ExponentialKernel" href="#KernelFunctions.ExponentialKernel"><code>KernelFunctions.ExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ExponentialKernel(; metric=Euclidean())</code></pre><p>Exponential kernel with respect to the <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the exponential kernel is defined as</p><p class="math-container">\[k(x, x&#39;) = \exp\big(- d(x, x&#39;)\big).\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>See also: <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponential.jl#L58-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GibbsKernel" href="#KernelFunctions.GibbsKernel"><code>KernelFunctions.GibbsKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GibbsKernel(; lengthscale)</code></pre><p>Gibbs Kernel with lengthscale function <code>lengthscale</code>.</p><p>The Gibbs kernel is a non-stationary generalisation of the squared exponential kernel. The lengthscale parameter <span>$l$</span> becomes a function of position <span>$l(x)$</span>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span>, the Gibbs kernel with lengthscale function <span>$l(\cdot)$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; l) = \sqrt{\left(\frac{2 l(x) l(x&#39;)}{l(x)^2 + l(x&#39;)^2}\right)}
\quad \exp{\left(-\frac{(x - x&#39;)^2}{l(x)^2 + l(x&#39;)^2}\right)}.\]</p><p>For a constant function <span>$l \equiv c$</span>, one recovers the <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> with lengthscale <code>c</code>.</p><p><strong>References</strong></p><p>Mark N. Gibbs. &quot;Bayesian Gaussian Processes for Regression and Classication.&quot; PhD thesis, 1997</p><p>Christopher J. Paciorek and Mark J. Schervish. &quot;Nonstationary Covariance Functions for Gaussian Process Regression&quot;. NeurIPS, 2003</p><p>Sami Remes, Markus Heinonen, Samuel Kaski. &quot;Non-Stationary Spectral Kernels&quot;. arXiV:1705.08736, 2017</p><p>Sami Remes, Markus Heinonen, Samuel Kaski. &quot;Neural Non-Stationary Spectral Kernel&quot;. arXiv:1811.10978, 2018</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/kernels/gibbskernel.jl#L1-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.LaplacianKernel" href="#KernelFunctions.LaplacianKernel"><code>KernelFunctions.LaplacianKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LaplacianKernel()</code></pre><p>Alias of <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponential.jl#L91-L95">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.SqExponentialKernel" href="#KernelFunctions.SqExponentialKernel"><code>KernelFunctions.SqExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SqExponentialKernel(; metric=Euclidean())</code></pre><p>Squared exponential kernel with respect to the <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the squared exponential kernel is defined as</p><p class="math-container">\[k(x, x&#39;) = \exp\bigg(- \frac{d(x, x&#39;)^2}{2}\bigg).\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>See also: <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponential.jl#L1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.SEKernel" href="#KernelFunctions.SEKernel"><code>KernelFunctions.SEKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SEKernel()</code></pre><p>Alias of <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponential.jl#L51-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GaussianKernel" href="#KernelFunctions.GaussianKernel"><code>KernelFunctions.GaussianKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GaussianKernel()</code></pre><p>Alias of <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponential.jl#L44-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.RBFKernel" href="#KernelFunctions.RBFKernel"><code>KernelFunctions.RBFKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RBFKernel()</code></pre><p>Alias of <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponential.jl#L37-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GammaExponentialKernel" href="#KernelFunctions.GammaExponentialKernel"><code>KernelFunctions.GammaExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GammaExponentialKernel(; γ::Real=1.0, metric=Euclidean())</code></pre><p>γ-exponential kernel with respect to the <code>metric</code> and with parameter <code>γ</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the γ-exponential kernel<sup class="footnote-reference"><a id="citeref-RW" href="#footnote-RW">[RW]</a></sup> with parameter <span>$\gamma \in (0, 2]$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; \gamma) = \exp\big(- d(x, x&#39;)^{\gamma}\big).\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>See also: <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a>, <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponential.jl#L105-L123">source</a></section></article><h3 id="Exponentiated-Kernel"><a class="docs-heading-anchor" href="#Exponentiated-Kernel">Exponentiated Kernel</a><a id="Exponentiated-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Exponentiated-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ExponentiatedKernel" href="#KernelFunctions.ExponentiatedKernel"><code>KernelFunctions.ExponentiatedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ExponentiatedKernel()</code></pre><p>Exponentiated kernel.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39; \in \mathbb{R}^d$</span>, the exponentiated kernel is defined as</p><p class="math-container">\[k(x, x&#39;) = \exp(x^\top x&#39;).\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponentiated.jl#L1-L12">source</a></section></article><h3 id="Fractional-Brownian-Motion-Kernel"><a class="docs-heading-anchor" href="#Fractional-Brownian-Motion-Kernel">Fractional Brownian Motion Kernel</a><a id="Fractional-Brownian-Motion-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Fractional-Brownian-Motion-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.FBMKernel" href="#KernelFunctions.FBMKernel"><code>KernelFunctions.FBMKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FBMKernel(; h::Real=0.5)</code></pre><p>Fractional Brownian motion kernel with Hurst index <code>h</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39; \in \mathbb{R}^d$</span>, the fractional Brownian motion kernel with <a href="https://en.wikipedia.org/wiki/Hurst_exponent#Generalized_exponent">Hurst index</a> <span>$h \in [0,1]$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; h) =  \frac{\|x\|_2^{2h} + \|x&#39;\|_2^{2h} - \|x - x&#39;\|^{2h}}{2}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/fbm.jl#L1-L14">source</a></section></article><h3 id="Gabor-Kernel"><a class="docs-heading-anchor" href="#Gabor-Kernel">Gabor Kernel</a><a id="Gabor-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Gabor-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.gaborkernel" href="#KernelFunctions.gaborkernel"><code>KernelFunctions.gaborkernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">gaborkernel(;
    sqexponential_transform=IdentityTransform(), cosine_tranform=IdentityTransform()
)</code></pre><p>Construct a Gabor kernel with transformations <code>sqexponential_transform</code> and <code>cosine_transform</code> of the inputs of the underlying squared exponential and cosine kernel, respectively.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39; \in \mathbb{R}^d$</span>, the Gabor kernel with transformations <span>$f$</span> and <span>$g$</span> of the inputs to the squared exponential and cosine kernel, respectively, is defined as</p><p class="math-container">\[k(x, x&#39;; f, g) = \exp\bigg(- \frac{\| f(x) - f(x&#39;)\|_2^2}{2}\bigg)
                 \cos\big(\pi \|g(x) - g(x&#39;)\|_2 \big).\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/gabor.jl#L1-L19">source</a></section></article><h3 id="Matérn-Kernels"><a class="docs-heading-anchor" href="#Matérn-Kernels">Matérn Kernels</a><a id="Matérn-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Matérn-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.MaternKernel" href="#KernelFunctions.MaternKernel"><code>KernelFunctions.MaternKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MaternKernel(; ν::Real=1.5, metric=Euclidean())</code></pre><p>Matérn kernel of order <code>ν</code> with respect to the <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the Matérn kernel of order <span>$\nu &gt; 0$</span> is defined as</p><p class="math-container">\[k(x,x&#39;;\nu) = \frac{2^{1-\nu}}{\Gamma(\nu)}\big(\sqrt{2\nu} d(x, x&#39;)\big) K_\nu\big(\sqrt{2\nu} d(x, x&#39;)\big),\]</p><p>where <span>$\Gamma$</span> is the Gamma function and <span>$K_{\nu}$</span> is the modified Bessel function of the second kind of order <span>$\nu$</span>. By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>A Gaussian process with a Matérn kernel is <span>$\lceil \nu \rceil - 1$</span>-times differentiable in the mean-square sense.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Differentiation with respect to the order ν is not currently supported.</p></div></div><p>See also: <a href="#KernelFunctions.Matern12Kernel"><code>Matern12Kernel</code></a>, <a href="#KernelFunctions.Matern32Kernel"><code>Matern32Kernel</code></a>, <a href="#KernelFunctions.Matern52Kernel"><code>Matern52Kernel</code></a>, <a href="#KernelFunctions.Matern72Kernel"><code>Matern72Kernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/matern.jl#L1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Matern12Kernel" href="#KernelFunctions.Matern12Kernel"><code>KernelFunctions.Matern12Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Matern12Kernel()</code></pre><p>Alias of <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/exponential.jl#L98-L102">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Matern32Kernel" href="#KernelFunctions.Matern32Kernel"><code>KernelFunctions.Matern32Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Matern32Kernel(; metric=Euclidean())</code></pre><p>Matérn kernel of order <span>$3/2$</span> with respect to the <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the Matérn kernel of order <span>$3/2$</span> is  given by</p><p class="math-container">\[k(x, x&#39;) = \big(1 + \sqrt{3} d(x, x&#39;) \big) \exp\big(- \sqrt{3} d(x, x&#39;) \big).\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>See also: <a href="#KernelFunctions.MaternKernel"><code>MaternKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/matern.jl#L61-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Matern52Kernel" href="#KernelFunctions.Matern52Kernel"><code>KernelFunctions.Matern52Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Matern52Kernel(; metric=Euclidean())</code></pre><p>Matérn kernel of order <span>$5/2$</span> with respect to the <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the Matérn kernel of order <span>$5/2$</span> is given by</p><p class="math-container">\[k(x, x&#39;) = \bigg(1 + \sqrt{5} d(x, x&#39;) + \frac{5}{3} d(x, x&#39;)^2\bigg)
           \exp\big(- \sqrt{5} d(x, x&#39;) \big).\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>See also: <a href="#KernelFunctions.MaternKernel"><code>MaternKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/matern.jl#L91-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Matern72Kernel" href="#KernelFunctions.Matern72Kernel"><code>KernelFunctions.Matern72Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Matern72Kernel(; metric=Euclidean())</code></pre><p>Matérn kernel of order <span>$7/2$</span> with respect to the <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the Matérn kernel of order <span>$7/2$</span> is given by</p><p class="math-container">\[k(x, x&#39;) = \bigg(1 + \sqrt{7} d(x, x&#39;) + \frac{14}{5} d(x, x&#39;)^2 + 
           \frac{7\sqrt{7}}{15} d(x, x&#39;)^3\bigg)\exp\big(- \sqrt{7} d(x, x&#39;) \big).\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>See also: <a href="#KernelFunctions.MaternKernel"><code>MaternKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/matern.jl#L122-L138">source</a></section></article><h3 id="Neural-Network-Kernel"><a class="docs-heading-anchor" href="#Neural-Network-Kernel">Neural Network Kernel</a><a id="Neural-Network-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Network-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.NeuralNetworkKernel" href="#KernelFunctions.NeuralNetworkKernel"><code>KernelFunctions.NeuralNetworkKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NeuralNetworkKernel()</code></pre><p>Kernel of a Gaussian process obtained as the limit of a Bayesian neural network with a single hidden layer as the number of units goes to infinity.</p><p><strong>Definition</strong></p><p>Consider the single-layer Bayesian neural network <span>$f \colon \mathbb{R}^d \to \mathbb{R}$</span> with <span>$h$</span> hidden units defined by</p><p class="math-container">\[f(x; b, v, u) = b + \sqrt{\frac{\pi}{2}} \sum_{i=1}^{h} v_i \mathrm{erf}\big(u_i^\top x\big),\]</p><p>where <span>$\mathrm{erf}$</span> is the error function, and with prior distributions</p><p class="math-container">\[\begin{aligned}
b &amp;\sim \mathcal{N}(0, \sigma_b^2),\\
v &amp;\sim \mathcal{N}(0, \sigma_v^2 \mathrm{I}_{h}/h),\\
u_i &amp;\sim \mathcal{N}(0, \mathrm{I}_{d}/2) \qquad (i = 1,\ldots,h).
\end{aligned}\]</p><p>As <span>$h \to \infty$</span>, the neural network converges to the Gaussian process</p><p class="math-container">\[g(\cdot) \sim \mathcal{GP}\big(0, \sigma_b^2 + \sigma_v^2 k(\cdot, \cdot)\big),\]</p><p>where the neural network kernel <span>$k$</span> is given by</p><p class="math-container">\[k(x, x&#39;) = \arcsin\left(\frac{x^\top x&#39;}{\sqrt{\big(1 + \|x\|^2_2\big) \big(1 + \|x&#39;\|_2^2\big)}}\right)\]</p><p>for inputs <span>$x, x&#39; \in \mathbb{R}^d$</span>.<sup class="footnote-reference"><a id="citeref-CW" href="#footnote-CW">[CW]</a></sup></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/nn.jl#L1-L33">source</a></section></article><h3 id="Periodic-Kernel"><a class="docs-heading-anchor" href="#Periodic-Kernel">Periodic Kernel</a><a id="Periodic-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Periodic-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PeriodicKernel" href="#KernelFunctions.PeriodicKernel"><code>KernelFunctions.PeriodicKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PeriodicKernel(; r::AbstractVector=ones(Float64, 1))</code></pre><p>Periodic kernel with parameter <code>r</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39; \in \mathbb{R}^d$</span>, the periodic kernel with parameter <span>$r_i &gt; 0$</span> is defined<sup class="footnote-reference"><a id="citeref-DM" href="#footnote-DM">[DM]</a></sup> as</p><p class="math-container">\[k(x, x&#39;; r) = \exp\bigg(- \frac{1}{2} \sum_{i=1}^d \bigg(\frac{\sin\big(\pi(x_i - x&#39;_i)\big)}{r_i}\bigg)^2\bigg).\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/periodic.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PeriodicKernel-Tuple{DataType, Int64}" href="#KernelFunctions.PeriodicKernel-Tuple{DataType, Int64}"><code>KernelFunctions.PeriodicKernel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">PeriodicKernel([T=Float64, dims::Int=1])</code></pre><p>Create a <a href="#KernelFunctions.PeriodicKernel"><code>PeriodicKernel</code></a> with parameter <code>r=ones(T, dims)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/periodic.jl#L26-L30">source</a></section></article><h3 id="Piecewise-Polynomial-Kernel"><a class="docs-heading-anchor" href="#Piecewise-Polynomial-Kernel">Piecewise Polynomial Kernel</a><a id="Piecewise-Polynomial-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Piecewise-Polynomial-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PiecewisePolynomialKernel" href="#KernelFunctions.PiecewisePolynomialKernel"><code>KernelFunctions.PiecewisePolynomialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PiecewisePolynomialKernel(; dim::Int, degree::Int=0, metric=Euclidean())
PiecewisePolynomialKernel{degree}(; dim::Int, metric=Euclidean())</code></pre><p>Piecewise polynomial kernel of degree <code>degree</code> for inputs of dimension <code>dim</code> with support in the unit ball with respect to the <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> of dimension <span>$m$</span> and metric <span>$d(\cdot, \cdot)$</span>, the piecewise polynomial kernel of degree <span>$v \in \{0,1,2,3\}$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; v) = \max(1 - d(x, x&#39;), 0)^{\alpha(v,m)} f_{v,m}(d(x, x&#39;)),\]</p><p>where <span>$\alpha(v, m) = \lfloor \frac{m}{2}\rfloor + 2v + 1$</span> and <span>$f_{v,m}$</span> are polynomials of degree <span>$v$</span> given by</p><p class="math-container">\[\begin{aligned}
f_{0,m}(r) &amp;= 1, \\
f_{1,m}(r) &amp;= 1 + (j + 1) r, \\
f_{2,m}(r) &amp;= 1 + (j + 2) r + \big((j^2 + 4j + 3) / 3\big) r^2, \\
f_{3,m}(r) &amp;= 1 + (j + 3) r + \big((6 j^2 + 36j + 45) / 15\big) r^2 + \big((j^3 + 9 j^2 + 23j + 15) / 15\big) r^3,
\end{aligned}\]</p><p>where <span>$j = \lfloor \frac{m}{2}\rfloor + v + 1$</span>. By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>The kernel is <span>$2v$</span> times continuously differentiable and the corresponding Gaussian process is hence <span>$v$</span> times mean-square differentiable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/piecewisepolynomial.jl#L1-L30">source</a></section></article><h3 id="Polynomial-Kernels"><a class="docs-heading-anchor" href="#Polynomial-Kernels">Polynomial Kernels</a><a id="Polynomial-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Polynomial-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.LinearKernel" href="#KernelFunctions.LinearKernel"><code>KernelFunctions.LinearKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LinearKernel(; c::Real=0.0)</code></pre><p>Linear kernel with constant offset <code>c</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39; \in \mathbb{R}^d$</span>, the linear kernel with constant offset <span>$c \geq 0$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; c) = x^\top x&#39; + c.\]</p><p>See also: <a href="#KernelFunctions.PolynomialKernel"><code>PolynomialKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/polynomial.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PolynomialKernel" href="#KernelFunctions.PolynomialKernel"><code>KernelFunctions.PolynomialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PolynomialKernel(; degree::Int=2, c::Real=0.0)</code></pre><p>Polynomial kernel of degree <code>degree</code> with constant offset <code>c</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39; \in \mathbb{R}^d$</span>, the polynomial kernel of degree <span>$\nu \in \mathbb{N}$</span> with constant offset <span>$c \geq 0$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; c, \nu) = (x^\top x&#39; + c)^\nu.\]</p><p>See also: <a href="#KernelFunctions.LinearKernel"><code>LinearKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/polynomial.jl#L53-L67">source</a></section></article><h3 id="Rational-Kernels"><a class="docs-heading-anchor" href="#Rational-Kernels">Rational Kernels</a><a id="Rational-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Rational-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.RationalKernel" href="#KernelFunctions.RationalKernel"><code>KernelFunctions.RationalKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RationalKernel(; α::Real=2.0, metric=Euclidean())</code></pre><p>Rational kernel with shape parameter <code>α</code> and given <code>metric</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the rational kernel with shape parameter <span>$\alpha &gt; 0$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; \alpha) = \bigg(1 + \frac{d(x, x&#39;)}{\alpha}\bigg)^{-\alpha}.\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>The <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a> is recovered in the limit as <span>$\alpha \to \infty$</span>.</p><p>See also: <a href="#KernelFunctions.GammaRationalKernel"><code>GammaRationalKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/rational.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.RationalQuadraticKernel" href="#KernelFunctions.RationalQuadraticKernel"><code>KernelFunctions.RationalQuadraticKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RationalQuadraticKernel(; α::Real=2.0, metric=Euclidean())</code></pre><p>Rational-quadratic kernel with respect to the <code>metric</code> and with shape parameter <code>α</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the rational-quadratic kernel with shape parameter <span>$\alpha &gt; 0$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; \alpha) = \bigg(1 + \frac{d(x, x&#39;)^2}{2\alpha}\bigg)^{-\alpha}.\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>The <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> is recovered in the limit as <span>$\alpha \to \infty$</span>.</p><p>See also: <a href="#KernelFunctions.GammaRationalKernel"><code>GammaRationalKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/rational.jl#L64-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GammaRationalKernel" href="#KernelFunctions.GammaRationalKernel"><code>KernelFunctions.GammaRationalKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GammaRationalKernel(; α::Real=2.0, γ::Real=1.0, metric=Euclidean())</code></pre><p>γ-rational kernel with respect to the <code>metric</code> with shape parameters <code>α</code> and <code>γ</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and metric <span>$d(\cdot, \cdot)$</span>, the γ-rational kernel with shape parameters <span>$\alpha &gt; 0$</span> and <span>$\gamma \in (0, 2]$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; \alpha, \gamma) = \bigg(1 + \frac{d(x, x&#39;)^{\gamma}}{\alpha}\bigg)^{-\alpha}.\]</p><p>By default, <span>$d$</span> is the Euclidean metric <span>$d(x, x&#39;) = \|x - x&#39;\|_2$</span>.</p><p>The <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a> is recovered in the limit as <span>$\alpha \to \infty$</span>.</p><p>See also: <a href="#KernelFunctions.RationalKernel"><code>RationalKernel</code></a>, <a href="#KernelFunctions.RationalQuadraticKernel"><code>RationalQuadraticKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/rational.jl#L151-L168">source</a></section></article><h3 id="Spectral-Mixture-Kernels"><a class="docs-heading-anchor" href="#Spectral-Mixture-Kernels">Spectral Mixture Kernels</a><a id="Spectral-Mixture-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Spectral-Mixture-Kernels" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.spectral_mixture_kernel" href="#KernelFunctions.spectral_mixture_kernel"><code>KernelFunctions.spectral_mixture_kernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">spectral_mixture_kernel(
    h::Kernel=SqExponentialKernel(),
    αs::AbstractVector{&lt;:Real},
    γs::AbstractMatrix{&lt;:Real},
    ωs::AbstractMatrix{&lt;:Real},
)</code></pre><p>where αs are the weights of dimension (A, ), γs is the covariance matrix of dimension (D, A) and ωs are the mean vectors and is of dimension (D, A). Here, D is input dimension and A is the number of spectral components.</p><p><code>h</code> is the kernel, which defaults to <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> if not specified.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>If you want to make sure that the constructor is type-stable, you should provide <a href="https://github.com/JuliaArrays/StaticArrays.jl"><code>StaticArrays</code></a> arguments: <code>αs</code> as a <code>StaticVector</code>, <code>γs</code> and <code>ωs</code> as <code>StaticMatrix</code>.</p></div></div><p>Generalised Spectral Mixture kernel function. This family of functions is  dense in the family of stationary real-valued kernels with respect to the pointwise convergence.[1]</p><p class="math-container">\[   κ(x, y) = αs&#39; (h(-(γs&#39; * t)^2) .* cos(π * ωs&#39; * t), t = x - y\]</p><p><strong>References:</strong></p><pre><code class="language-julia hljs">[1] Generalized Spectral Kernels, by Yves-Laurent Kom Samo and Stephen J. Roberts
[2] SM: Gaussian Process Kernels for Pattern Discovery and Extrapolation,
        ICML, 2013, by Andrew Gordon Wilson and Ryan Prescott Adams,
[3] Covariance kernels for fast automatic pattern discovery and extrapolation
    with Gaussian processes, Andrew Gordon Wilson, PhD Thesis, January 2014.
    http://www.cs.cmu.edu/~andrewgw/andrewgwthesis.pdf
[4] http://www.cs.cmu.edu/~andrewgw/pattern/.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/sm.jl#L1-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.spectral_mixture_product_kernel" href="#KernelFunctions.spectral_mixture_product_kernel"><code>KernelFunctions.spectral_mixture_product_kernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">spectral_mixture_product_kernel(
    h::Kernel=SqExponentialKernel(),
    αs::AbstractMatrix{&lt;:Real},
    γs::AbstractMatrix{&lt;:Real},
    ωs::AbstractMatrix{&lt;:Real},
)</code></pre><p>where αs are the weights of dimension (D, A), γs is the covariance matrix of dimension (D, A) and ωs are the mean vectors and is of dimension (D, A). Here, D is input dimension and A is the number of spectral components.</p><p>Spectral Mixture Product Kernel. With enough components A, the SMP kernel can model any product kernel to arbitrary precision, and is flexible even with a small number of components [1]</p><p><code>h</code> is the kernel, which defaults to <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> if not specified.</p><p class="math-container">\[   κ(x, y) = Πᵢ₌₁ᴷ Σ(αsᵢᵀ .* (h(-(γsᵢᵀ * tᵢ)²) .* cos(ωsᵢᵀ * tᵢ))), tᵢ = xᵢ - yᵢ\]</p><p><strong>References:</strong></p><pre><code class="language-julia hljs">[1] GPatt: Fast Multidimensional Pattern Extrapolation with GPs,
    arXiv 1310.5288, 2013, by Andrew Gordon Wilson, Elad Gilboa,
    Arye Nehorai and John P. Cunningham</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/sm.jl#L64-L91">source</a></section></article><h3 id="Wiener-Kernel"><a class="docs-heading-anchor" href="#Wiener-Kernel">Wiener Kernel</a><a id="Wiener-Kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Wiener-Kernel" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.WienerKernel" href="#KernelFunctions.WienerKernel"><code>KernelFunctions.WienerKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WienerKernel(; i::Int=0)
WienerKernel{i}()</code></pre><p>The <code>i</code>-times integrated Wiener process kernel function.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39; \in \mathbb{R}^d$</span>, the <span>$i$</span>-times integrated Wiener process kernel with <span>$i \in \{-1, 0, 1, 2, 3\}$</span> is defined<sup class="footnote-reference"><a id="citeref-SDH" href="#footnote-SDH">[SDH]</a></sup> as</p><p class="math-container">\[k_i(x, x&#39;) = \begin{cases}
    \delta(x, x&#39;) &amp; \text{if } i=-1,\\
    \min\big(\|x\|_2, \|x&#39;\|_2\big) &amp; \text{if } i=0,\\
    a_{i1}^{-1} \min\big(\|x\|_2, \|x&#39;\|_2\big)^{2i + 1}
    + a_{i2}^{-1} \|x - x&#39;\|_2 r_i\big(\|x\|_2, \|x&#39;\|_2\big) \min\big(\|x\|_2, \|x&#39;\|_2\big)^{i + 1}
    &amp; \text{otherwise},
\end{cases}\]</p><p>where the coefficients <span>$a$</span> are given by</p><p class="math-container">\[a = \begin{bmatrix}
3 &amp; 2 \\
20 &amp; 12 \\
252 &amp; 720
\end{bmatrix}\]</p><p>and the functions <span>$r_i$</span> are defined as</p><p class="math-container">\[\begin{aligned}
r_1(t, t&#39;) &amp;= 1,\\
r_2(t, t&#39;) &amp;= t + t&#39; - \frac{\min(t, t&#39;)}{2},\\
r_3(t, t&#39;) &amp;= 5 \max(t, t&#39;)^2 + 2 tt&#39; + 3 \min(t, t&#39;)^2.
\end{aligned}\]</p><p>The <a href="#KernelFunctions.WhiteKernel"><code>WhiteKernel</code></a> is recovered for <span>$i = -1$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/basekernels/wiener.jl#L1-L40">source</a></section></article><h2 id="Composite-Kernels"><a class="docs-heading-anchor" href="#Composite-Kernels">Composite Kernels</a><a id="Composite-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Composite-Kernels" title="Permalink"></a></h2><p>The modular design of KernelFunctions uses <a href="#base_kernels">base kernels</a> as building blocks for more complex kernels. There are a variety of composite kernels implemented, including those which <a href="../transform/#input_transforms">transform the inputs</a> to a wrapped kernel to implement length scales, scale the variance of a kernel, and sum or multiply collections of kernels together.</p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.TransformedKernel" href="#KernelFunctions.TransformedKernel"><code>KernelFunctions.TransformedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TransformedKernel(k::Kernel, t::Transform)</code></pre><p>Kernel derived from <code>k</code> for which inputs are transformed via a <a href="../transform/#KernelFunctions.Transform"><code>Transform</code></a> <code>t</code>.</p><p>The preferred way to create kernels with input transformations is to use the composition operator <a href="#Base.:∘-Tuple{Kernel, Transform}"><code>∘</code></a> or its alias <code>compose</code> instead of <code>TransformedKernel</code> directly since this allows optimized implementations for specific kernels and transformations.</p><p>See also: <a href="#Base.:∘-Tuple{Kernel, Transform}"><code>∘</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/kernels/transformedkernel.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:∘-Tuple{Kernel, Transform}" href="#Base.:∘-Tuple{Kernel, Transform}"><code>Base.:∘</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">kernel ∘ transform
∘(kernel, transform)
compose(kernel, transform)</code></pre><p>Compose a <code>kernel</code> with a transformation <code>transform</code> of its inputs.</p><p>The prefix forms support chains of multiple transformations: <code>∘(kernel, transform1, transform2) = kernel ∘ transform1 ∘ transform2</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span>, the transformed kernel <span>$\widetilde{k}$</span> derived from kernel <span>$k$</span> by input transformation <span>$t$</span> is defined as</p><p class="math-container">\[\widetilde{k}(x, x&#39;; k, t) = k\big(t(x), t(x&#39;)\big).\]</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; (SqExponentialKernel() ∘ ScaleTransform(0.5))(0, 2) == exp(-0.5)
true

julia&gt; ∘(ExponentialKernel(), ScaleTransform(2), ScaleTransform(0.5))(1, 2) == exp(-1)
true</code></pre><p>See also: <a href="#KernelFunctions.TransformedKernel"><code>TransformedKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/kernels/transformedkernel.jl#L38-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ScaledKernel" href="#KernelFunctions.ScaledKernel"><code>KernelFunctions.ScaledKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ScaledKernel(k::Kernel, σ²::Real=1.0)</code></pre><p>Scaled kernel derived from <code>k</code> by multiplication with variance <code>σ²</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span>, the scaled kernel <span>$\widetilde{k}$</span> derived from kernel <span>$k$</span> by multiplication with variance <span>$\sigma^2 &gt; 0$</span> is defined as</p><p class="math-container">\[\widetilde{k}(x, x&#39;; k, \sigma^2) = \sigma^2 k(x, x&#39;).\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/kernels/scaledkernel.jl#L1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelSum" href="#KernelFunctions.KernelSum"><code>KernelFunctions.KernelSum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">KernelSum &lt;: Kernel</code></pre><p>Create a sum of kernels. One can also use the operator <code>+</code>.</p><p>There are various ways in which you create a <code>KernelSum</code>:</p><p>The simplest way to specify a <code>KernelSum</code> would be to use the overloaded <code>+</code> operator. This is  equivalent to creating a <code>KernelSum</code> by specifying the kernels as the arguments to the constructor.  </p><pre><code class="language-julia-repl hljs">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5);

julia&gt; (k = k1 + k2) == KernelSum(k1, k2)
true

julia&gt; kernelmatrix(k1 + k2, X) == kernelmatrix(k1, X) .+ kernelmatrix(k2, X)
true

julia&gt; kernelmatrix(k, X) == kernelmatrix(k1 + k2, X)
true</code></pre><p>You could also specify a <code>KernelSum</code> by providing a <code>Tuple</code> or a <code>Vector</code> of the  kernels to be summed. We suggest you to use a <code>Tuple</code> when you have fewer components   and a <code>Vector</code> when dealing with a large number of components.</p><pre><code class="language-julia-repl hljs">julia&gt; KernelSum((k1, k2)) == k1 + k2
true

julia&gt; KernelSum([k1, k2]) == KernelSum((k1, k2)) == k1 + k2
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/kernels/kernelsum.jl#L1-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelProduct" href="#KernelFunctions.KernelProduct"><code>KernelFunctions.KernelProduct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">KernelProduct &lt;: Kernel</code></pre><p>Create a product of kernels. One can also use the overloaded operator <code>*</code>.</p><p>There are various ways in which you create a <code>KernelProduct</code>:</p><p>The simplest way to specify a <code>KernelProduct</code> would be to use the overloaded <code>*</code> operator. This is  equivalent to creating a <code>KernelProduct</code> by specifying the kernels as the arguments to the constructor.  </p><pre><code class="language-julia-repl hljs">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5);

julia&gt; (k = k1 * k2) == KernelProduct(k1, k2)
true

julia&gt; kernelmatrix(k1 * k2, X) == kernelmatrix(k1, X) .* kernelmatrix(k2, X)
true

julia&gt; kernelmatrix(k, X) == kernelmatrix(k1 * k2, X)
true</code></pre><p>You could also specify a <code>KernelProduct</code> by providing a <code>Tuple</code> or a <code>Vector</code> of the  kernels to be multiplied. We suggest you to use a <code>Tuple</code> when you have fewer components   and a <code>Vector</code> when dealing with a large number of components.</p><pre><code class="language-julia-repl hljs">julia&gt; KernelProduct((k1, k2)) == k1 * k2
true

julia&gt; KernelProduct([k1, k2]) == KernelProduct((k1, k2)) == k1 * k2
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/kernels/kernelproduct.jl#L1-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelTensorProduct" href="#KernelFunctions.KernelTensorProduct"><code>KernelFunctions.KernelTensorProduct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">KernelTensorProduct</code></pre><p>Tensor product of kernels.</p><p><strong>Definition</strong></p><p>For inputs <span>$x = (x_1, \ldots, x_n)$</span> and <span>$x&#39; = (x&#39;_1, \ldots, x&#39;_n)$</span>, the tensor product of kernels <span>$k_1, \ldots, k_n$</span> is defined as</p><p class="math-container">\[k(x, x&#39;; k_1, \ldots, k_n) = \Big(\bigotimes_{i=1}^n k_i\Big)(x, x&#39;) = \prod_{i=1}^n k_i(x_i, x&#39;_i).\]</p><p><strong>Construction</strong></p><p>The simplest way to specify a <code>KernelTensorProduct</code> is to use the overloaded <code>tensor</code> operator or its alias <code>⊗</code> (can be typed by <code>\otimes&lt;tab&gt;</code>).</p><pre><code class="language-julia-repl hljs">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5, 2);

julia&gt; kernelmatrix(k1 ⊗ k2, RowVecs(X)) == kernelmatrix(k1, X[:, 1]) .* kernelmatrix(k2, X[:, 2])
true</code></pre><p>You can also specify a <code>KernelTensorProduct</code> by providing kernels as individual arguments or as an iterable data structure such as a <code>Tuple</code> or a <code>Vector</code>. Using a tuple or individual arguments guarantees that <code>KernelTensorProduct</code> is concretely typed but might lead to large compilation times if the number of kernels is large.</p><pre><code class="language-julia-repl hljs">julia&gt; KernelTensorProduct(k1, k2) == k1 ⊗ k2
true

julia&gt; KernelTensorProduct((k1, k2)) == k1 ⊗ k2
true

julia&gt; KernelTensorProduct([k1, k2]) == k1 ⊗ k2
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/kernels/kerneltensorproduct.jl#L1-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.NormalizedKernel" href="#KernelFunctions.NormalizedKernel"><code>KernelFunctions.NormalizedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NormalizedKernel(k::Kernel)</code></pre><p>A normalized kernel derived from <code>k</code>.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span>, the normalized kernel <span>$\widetilde{k}$</span> derived from kernel <span>$k$</span> is defined as</p><p class="math-container">\[\widetilde{k}(x, x&#39;; k) = \frac{k(x, x&#39;)}{\sqrt{k(x, x) k(x&#39;, x&#39;)}}.\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/kernels/normalizedkernel.jl#L1-L13">source</a></section></article><h2 id="Multi-output-Kernels"><a class="docs-heading-anchor" href="#Multi-output-Kernels">Multi-output Kernels</a><a id="Multi-output-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-output-Kernels" title="Permalink"></a></h2><p>Kernelfunctions implements multi-output kernels as scalar kernels on an extended output domain. For more details on this read <a href="../api/#Inputs-for-Multiple-Outputs">the section on inputs for multi-output GPs</a>.</p><p>For a function <span>$f(x) \rightarrow y$</span> denote the inputs as <span>$x, x&#39;$</span>, such that we compute the covariance between output components <span>$y_{p}$</span> and <span>$y_{p&#39;}$</span>. The total number of outputs is <span>$m$</span>.</p><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.MOKernel" href="#KernelFunctions.MOKernel"><code>KernelFunctions.MOKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MOKernel</code></pre><p>Abstract type for kernels with multiple outpus.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/mokernels/mokernel.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.IndependentMOKernel" href="#KernelFunctions.IndependentMOKernel"><code>KernelFunctions.IndependentMOKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">IndependentMOKernel(k::Kernel)</code></pre><p>Kernel for multiple independent outputs with kernel <code>k</code> each.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and output dimensions <span>$p, p&#39;$</span>, the kernel <span>$\widetilde{k}$</span> for independent outputs with kernel <span>$k$</span> each is defined as</p><p class="math-container">\[\widetilde{k}\big((x, p), (x&#39;, p&#39;)\big) = \begin{cases}
    k(x, x&#39;) &amp; \text{if } p = p&#39;, \\
    0 &amp; \text{otherwise}.
\end{cases}\]</p><p>Mathematically, it is equivalent to a matrix-valued kernel defined as</p><p class="math-container">\[\widetilde{K}(x, x&#39;) = \mathrm{diag}\big(k(x, x&#39;), \ldots, k(x, x&#39;)\big) \in \mathbb{R}^{m \times m},\]</p><p>where <span>$m$</span> is the number of outputs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/mokernels/independent.jl#L1-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.LatentFactorMOKernel" href="#KernelFunctions.LatentFactorMOKernel"><code>KernelFunctions.LatentFactorMOKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LatentFactorMOKernel(g::AbstractVector{&lt;:Kernel}, e::MOKernel, A::AbstractMatrix)</code></pre><p>Kernel associated with the semiparametric latent factor model.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and output dimensions <span>$p_x, p_{x&#39;}&#39;$</span>, the kernel is defined as<sup class="footnote-reference"><a id="citeref-STJ" href="#footnote-STJ">[STJ]</a></sup></p><p class="math-container">\[k\big((x, p_x), (x, p_{x&#39;})\big) = \sum^{Q}_{q=1} A_{p_xq}g_q(x, x&#39;)A_{p_{x&#39;}q}
                                   + e\big((x, p_x), (x&#39;, p_{x&#39;})\big),\]</p><p>where <span>$g_1, \ldots, g_Q$</span> are <span>$Q$</span> kernels, one for each latent process, <span>$e$</span> is a multi-output kernel for <span>$m$</span> outputs, and <span>$A$</span> is a matrix of weights for the kernels of size <span>$m \times Q$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/mokernels/slfm.jl#L1-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.IntrinsicCoregionMOKernel" href="#KernelFunctions.IntrinsicCoregionMOKernel"><code>KernelFunctions.IntrinsicCoregionMOKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">IntrinsicCoregionMOKernel(; kernel::Kernel, B::AbstractMatrix)</code></pre><p>Kernel associated with the intrinsic coregionalization model.</p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and output dimensions <span>$p, p&#39;$</span>, the kernel is defined as<sup class="footnote-reference"><a id="citeref-ARL" href="#footnote-ARL">[ARL]</a></sup></p><p class="math-container">\[k\big((x, p), (x&#39;, p&#39;); B, \tilde{k}\big) = B_{p, p&#39;} \tilde{k}\big(x, x&#39;\big),\]</p><p>where <span>$B$</span> is a positive semidefinite matrix of size <span>$m \times m$</span>, with <span>$m$</span> being the number of outputs, and <span>$\tilde{k}$</span> is a scalar-valued kernel shared by the latent processes.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/mokernels/intrinsiccoregion.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.LinearMixingModelKernel" href="#KernelFunctions.LinearMixingModelKernel"><code>KernelFunctions.LinearMixingModelKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LinearMixingModelKernel(k::Kernel, H::AbstractMatrix)
LinearMixingModelKernel(Tk::AbstractVector{&lt;:Kernel},Th::AbstractMatrix)</code></pre><p>Kernel associated with the linear mixing model, taking a vector of <code>Q</code> kernels and a <code>Q × m</code> mixing matrix H for a function with <code>m</code> outputs. Also accepts a single kernel <code>k</code> for use across all <code>Q</code> basis vectors. </p><p><strong>Definition</strong></p><p>For inputs <span>$x, x&#39;$</span> and output dimensions <span>$p, p&#39;$</span>, the kernel is defined as<sup class="footnote-reference"><a id="citeref-BPTHST" href="#footnote-BPTHST">[BPTHST]</a></sup></p><p class="math-container">\[k\big((x, p), (x, p&#39;)\big) = H_{:,p}K(x, x&#39;)H_{:,p&#39;}\]</p><p>where <span>$K(x, x&#39;) = Diag(k_1(x, x&#39;), ..., k_Q(x, x&#39;))$</span> with zero off-diagonal entries. <span>$H_{:,p}$</span> is the <span>$p$</span>-th column (<code>p</code>-th output) of <span>$H \in \mathbb{R}^{Q \times m}$</span> representing <span>$Q$</span> basis vectors for the <span>$m$</span> dimensional output space of <span>$f$</span>. <span>$k_1, \ldots, k_Q$</span> are <span>$Q$</span> kernels, one for each latent process, <span>$H$</span> is a mixing matrix of <span>$Q$</span> basis vectors spanning the output space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/823219b18371c8fa7e761abd2eb9c600cef5d0bd/src/mokernels/lmm.jl#L1-L20">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-RW"><a class="tag is-link" href="#citeref-RW">RW</a>C. E. Rasmussen &amp; C. K. I. Williams (2006). Gaussian Processes for Machine Learning.</li><li class="footnote" id="footnote-CW"><a class="tag is-link" href="#citeref-CW">CW</a>C. K. I. Williams (1998). Computation with infinite neural networks.</li><li class="footnote" id="footnote-DM"><a class="tag is-link" href="#citeref-DM">DM</a>D. J. C. MacKay (1998). Introduction to Gaussian Processes.</li><li class="footnote" id="footnote-SDH"><a class="tag is-link" href="#citeref-SDH">SDH</a>Schober, Duvenaud &amp; Hennig (2014). Probabilistic ODE Solvers with Runge-Kutta Means.</li><li class="footnote" id="footnote-STJ"><a class="tag is-link" href="#citeref-STJ">STJ</a>M. Seeger, Y. Teh, &amp; M. I. Jordan (2005). <a href="https://infoscience.epfl.ch/record/161465/files/slfm-long.pdf">Semiparametric Latent Factor Models</a>.</li><li class="footnote" id="footnote-ARL"><a class="tag is-link" href="#citeref-ARL">ARL</a>M. Álvarez, L. Rosasco, &amp; N. Lawrence (2012). <a href="https://arxiv.org/pdf/1106.6251.pdf">Kernels for Vector-Valued Functions: a Review</a>.</li><li class="footnote" id="footnote-BPTHST"><a class="tag is-link" href="#citeref-BPTHST">BPTHST</a>Wessel P. Bruinsma, Eric Perim, Will Tebbutt, J. Scott Hosking, Arno Solin, Richard E. Turner (2020). <a href="https://arxiv.org/pdf/1911.06287.pdf">Scalable Exact Inference in Multi-Output Gaussian Processes</a>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../userguide/">« User guide</a><a class="docs-footer-nextpage" href="../transform/">Input Transforms »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Wednesday 15 October 2025 09:02">Wednesday 15 October 2025</span>. Using Julia version 1.12.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
