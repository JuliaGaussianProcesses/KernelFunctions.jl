<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Design · KernelFunctions.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">KernelFunctions.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../userguide/">User guide</a></li><li><a class="tocitem" href="../kernels/">Kernel Functions</a></li><li><a class="tocitem" href="../transform/">Input Transforms</a></li><li><a class="tocitem" href="../metrics/">Metrics</a></li><li><a class="tocitem" href="../create_kernel/">Custom Kernels</a></li><li><a class="tocitem" href="../api/">API</a></li><li class="is-active"><a class="tocitem" href>Design</a><ul class="internal"><li><a class="tocitem" href="#why_abstract_vectors"><span>Why AbstractVectors Everywhere?</span></a></li><li><a class="tocitem" href="#inputs_for_multiple_outputs"><span>Kernels for Multiple-Outputs</span></a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/gaussian-process-priors/">Gaussian process prior samples</a></li><li><a class="tocitem" href="../examples/kernel-ridge-regression/">Kernel Ridge Regression</a></li><li><a class="tocitem" href="../examples/support-vector-machine/">Support Vector Machine</a></li><li><a class="tocitem" href="../examples/train-kernel-parameters/">Train Kernel Parameters</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Design</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Design</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/master/docs/src/design.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Design"><a class="docs-heading-anchor" href="#Design">Design</a><a id="Design-1"></a><a class="docs-heading-anchor-permalink" href="#Design" title="Permalink"></a></h1><h2 id="why_abstract_vectors"><a class="docs-heading-anchor" href="#why_abstract_vectors">Why AbstractVectors Everywhere?</a><a id="why_abstract_vectors-1"></a><a class="docs-heading-anchor-permalink" href="#why_abstract_vectors" title="Permalink"></a></h2><p>To understand the advantages of using <code>AbstractVector</code>s everywhere to represent collections of inputs, first consider the following properties that it is desirable for a collection of inputs to satisfy.</p><h4 id="Unique-Ordering"><a class="docs-heading-anchor" href="#Unique-Ordering">Unique Ordering</a><a id="Unique-Ordering-1"></a><a class="docs-heading-anchor-permalink" href="#Unique-Ordering" title="Permalink"></a></h4><p>There must be a clearly-defined first, second, etc element of an input collection. If this were not the case, it would not be possible to determine a unique mapping between a collection of inputs and the output of <code>kernelmatrix</code>, as it would not be clear what order the rows and columns of the output should appear in.</p><p>Moreover, ordering guarantees that if you permute the collection of inputs, the ordering of the rows and columns of the <code>kernelmatrix</code> are correspondingly permuted.</p><h4 id="Generality"><a class="docs-heading-anchor" href="#Generality">Generality</a><a id="Generality-1"></a><a class="docs-heading-anchor-permalink" href="#Generality" title="Permalink"></a></h4><p>There must be no restriction on the domain of the input. Collections of <code>Real</code>s, vectors, graphs, finite-dimensional domains, or really anything else that you fancy should be straightforwardly representable. Moreover, whichever input class is chosen should not prevent optimal performance from being obtained.</p><h4 id="Unambiguously-Defined-Length"><a class="docs-heading-anchor" href="#Unambiguously-Defined-Length">Unambiguously-Defined Length</a><a id="Unambiguously-Defined-Length-1"></a><a class="docs-heading-anchor-permalink" href="#Unambiguously-Defined-Length" title="Permalink"></a></h4><p>Knowing the length of a collection of inputs is important. For example, a well-defined length guarantees that the size of the output of <code>kernelmatrix</code>, and related functions, are predictable. It also makes it possible to perform internal error-checking that ensures that e.g. there are the same number of inputs in two collections of inputs.</p><h3 id="AbstractMatrices-Do-Not-Cut-It"><a class="docs-heading-anchor" href="#AbstractMatrices-Do-Not-Cut-It">AbstractMatrices Do Not Cut It</a><a id="AbstractMatrices-Do-Not-Cut-It-1"></a><a class="docs-heading-anchor-permalink" href="#AbstractMatrices-Do-Not-Cut-It" title="Permalink"></a></h3><p>Notably, while <code>AbstractMatrix</code> objects are often used to represent collections of vector-valued inputs, they do <em>not</em> immediately satisfy these properties as it is unclear whether a matrix of size <code>P x Q</code> represents a collection of <code>P</code> <code>Q</code>-dimensional inputs (each row is an input), or <code>Q</code> <code>P</code>-dimensional inputs (each column is an input).</p><p>Moreover, they occasionally add some aesthetic inconvenience. For example, a collection of <code>Real</code>-valued inputs, which might be straightforwardly represented as an <code>AbstractVector{&lt;:Real}</code>, must be reshaped into a matrix.</p><p>There are two commonly used ways to partly resolve these shortcomings:</p><h4 id="Resolution-1:-Specify-a-Convention"><a class="docs-heading-anchor" href="#Resolution-1:-Specify-a-Convention">Resolution 1: Specify a Convention</a><a id="Resolution-1:-Specify-a-Convention-1"></a><a class="docs-heading-anchor-permalink" href="#Resolution-1:-Specify-a-Convention" title="Permalink"></a></h4><p>One way that these shortcomings can be partly resolved is by specifying a convention that everyone adheres to regarding the interpretation of rows vs columns. However, opinions about the choice of convention are often surprisingly strongly held, and users regularly have to remind themselves <em>which</em> convention has been chosen. While this resolves the ordering problem, and in principle defines the &quot;length&quot; of a collection of inputs, <code>AbstractMatrix</code>s already have a <code>length</code> defined in Julia, which would generally disagree with our internal notion of <code>length</code>. This isn&#39;t a show-stopper, but it isn&#39;t an especially clean situation.</p><p>There is also the opportunity for some kinds of silent bugs. For example, if an input matrix happens to be square because the number of input dimensions is the same as the number of inputs, it would be hard to know whether the correct <code>kernelmatrix</code> has been computed. This kind of bug seems unlikely, but it exists regardless.</p><p>Finally, suppose that your inputs are some type <code>T</code> that is not simply a vector of real numbers, say a graph. In this situation, how should a collection of inputs be represented? A <code>N x 1</code> or <code>1 x N</code> matrix is the only obvious candidate, but the additional singular dimension seems somewhat redundant.</p><h4 id="Resolution-2:-Always-Specify-An-obsdim-Argument"><a class="docs-heading-anchor" href="#Resolution-2:-Always-Specify-An-obsdim-Argument">Resolution 2: Always Specify An <code>obsdim</code> Argument</a><a id="Resolution-2:-Always-Specify-An-obsdim-Argument-1"></a><a class="docs-heading-anchor-permalink" href="#Resolution-2:-Always-Specify-An-obsdim-Argument" title="Permalink"></a></h4><p>Another way to partly resolve these problems is to not commit to a convention, and instead to propagate some additional information through the codebase that specifies how the input data is to be interpreted. For example, a kernel <code>k</code> that represents the sum of two other kernels might implement <code>kernelmatrix</code> as follows:</p><pre><code class="language-julia hljs">function kernelmatrix(k::KernelSum, x::AbstractMatrix; obsdim=1)
    return kernelmatrix(k.kernels[1], x; obsdim=obsdim) +
        kernelmatrix(k.kernels[2], x; obsdim=obsdim)
end</code></pre><p>While this prevents this package from having to pre-specify a convention, it doesn&#39;t resolve the <code>length</code> issue, or the issue of representing collections of inputs which aren&#39;t immediately represented as vectors. Moreover, it complicates the internals; in contrast, consider what this function looks like with an <code>AbstractVector</code>:</p><pre><code class="language-julia hljs">function kernelmatrix(k::KernelSum, x::AbstractVector)
    return kernelmatrix(k.kernels[1], x) + kernelmatrix(k.kernels[2], x)
end</code></pre><p>This code is clearer (less visual noise), and has removed a possible bug – if the implementer of <code>kernelmatrix</code> forgets to pass the <code>obsdim</code> kwarg into each subsequent <code>kernelmatrix</code> call, it&#39;s possible to get the wrong answer.</p><p>This being said, we do support matrix-valued inputs – see <a href="#Why-We-Have-Support-for-Both">Why We Have Support for Both</a>.</p><h3 id="AbstractVectors"><a class="docs-heading-anchor" href="#AbstractVectors">AbstractVectors</a><a id="AbstractVectors-1"></a><a class="docs-heading-anchor-permalink" href="#AbstractVectors" title="Permalink"></a></h3><p>Requiring all collections of inputs to be <code>AbstractVector</code>s resolves all of these problems, and ensures that the data is self-describing to the extent that KernelFunctions.jl requires.</p><p>Firstly, the question of how to interpret the columns and rows of a matrix of inputs is resolved. Users <em>must</em> wrap matrices which represent collections of inputs in either a <code>ColVecs</code> or <code>RowVecs</code>, both of which have clearly defined semantics which are hard to confuse.</p><p>By design, there is also no discrepancy between the number of inputs in the collection, and the <code>length</code> function – the <code>length</code> of a <code>ColVecs</code>, <code>RowVecs</code>, or <code>Vector{&lt;:Real}</code> is equal to the number of inputs.</p><p>There is no loss of performance.</p><p>A collection of <code>N</code> <code>Real</code>-valued inputs can be represented by an <code>AbstractVector{&lt;:Real}</code> of <code>length</code> <code>N</code>, rather than needing to use an <code>AbstractMatrix{&lt;:Real}</code> of size either <code>N x 1</code> or <code>1 x N</code>. The same can be said for any other input type <code>T</code>, and new subtypes of <code>AbstractVector</code> can be added if particularly efficient ways exist to store collections of inputs of type <code>T</code>. A good example of this in practice is using <code>Tuple{S, Int}</code>, for some input type <code>S</code>, as the <a href="../api/#Inputs-for-Multiple-Outputs">Inputs for Multiple Outputs</a>.</p><p>This approach can also lead to clearer user code. A user need only wrap their inputs in a <code>ColVecs</code> or <code>RowVecs</code> once in their code, and this specification is automatically re-used <em>everywhere</em> in their code. In this sense, it is straightforward to write code in such a way that there is one unique source of &quot;truth&quot; about the way in which a particular data set should be interpreted. Conversely, the <code>obsdim</code> resolution requires that the <code>obsdim</code> keyword argument is passed around with the data <em>every</em> <em>single</em> <em>time</em> that you use it.</p><p>The benefits of the <code>AbstractVector</code> approach are likely most strongly felt when writing a substantial amount of code on top of KernelFunctions.jl – in the same way that using <code>AbstractVector</code>s inside KernelFunctions.jl removes the need for large amounts of keyword argument propagation, the same will be true of other code.</p><h3 id="Why-We-Have-Support-for-Both"><a class="docs-heading-anchor" href="#Why-We-Have-Support-for-Both">Why We Have Support for Both</a><a id="Why-We-Have-Support-for-Both-1"></a><a class="docs-heading-anchor-permalink" href="#Why-We-Have-Support-for-Both" title="Permalink"></a></h3><p>In short: many people like matrices, and are familiar with <code>obsdim</code>-style keyword arguments.</p><p>All internals are implemented using <code>AbstractVector</code>s though, and the <code>obsdim</code> interface is just a thin layer of utility functionality which sits on top of this. To avoid confusion and silent errors, we do not favour a specific convention (rows or columns) but instead it is necessary to specify the <code>obsdim</code> keyword argument explicitly.</p><h2 id="inputs_for_multiple_outputs"><a class="docs-heading-anchor" href="#inputs_for_multiple_outputs">Kernels for Multiple-Outputs</a><a id="inputs_for_multiple_outputs-1"></a><a class="docs-heading-anchor-permalink" href="#inputs_for_multiple_outputs" title="Permalink"></a></h2><p>There are two equally-valid perspectives on multi-output kernels: they can either be treated as matrix-valued kernels, or standard kernels on an extended input domain. Each of these perspectives are convenient in different circumstances, but the latter greatly simplifies the incorporation of multi-output kernels in KernelFunctions.</p><p>More concretely, let <code>k_mat</code> be a matrix-valued kernel, mapping pairs of inputs of type <code>T</code> to matrices of size <code>P x P</code> to describe the covariance between <code>P</code> outputs. Given inputs <code>x</code> and <code>y</code> of type <code>T</code>, and integers <code>p</code> and <code>q</code>, we can always find an equivalent standard kernel <code>k</code> mapping from pairs of inputs of type <code>Tuple{T, Int}</code> to the <code>Real</code>s as follows:</p><pre><code class="language-julia hljs">k((x, p), (y, q)) = k_mat(x, y)[p, q]</code></pre><p>This ability to treat multi-output kernels as single-output kernels is very helpful, as it means that there is no need to introduce additional concepts into the API of KernelFunctions.jl, just additional kernels! This in turn simplifies downstream code as they don&#39;t need to &quot;know&quot; about the existence of multi-output kernels in addition to standard kernels. For example, GP libraries built on top of KernelFunctions.jl just need to know about <code>Kernel</code>s, and they get multi-output kernels, and hence multi-output GPs, for free.</p><p>Where there is the need to specialise <em>implementations</em> for multi-output kernels, this is done in an encapsulated manner – parts of KernelFunctions that have nothing to do with multi-output kernels know <em>nothing</em> about the existence of multi-output kernels.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../api/">« API</a><a class="docs-footer-nextpage" href="../examples/gaussian-process-priors/">Gaussian process prior samples »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Tuesday 13 January 2026 13:42">Tuesday 13 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
