var documenterSearchIndex = {"docs":
[{"location":"metrics/#Metrics-1","page":"Metrics","title":"Metrics","text":"","category":"section"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"KernelFunctions.jl relies on Distances.jl for computing the pairwise matrix. To do so a distance measure is needed for each kernel. Two very common ones can already be used : SqEuclidean and Euclidean. However all kernels do not rely on distances metrics respecting all the definitions. That's why two additional metrics come with the package : DotProduct (<x,y>) and Delta (δ(x,y)). If you want to create a new distance just implement the following :","category":"page"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"struct Delta <: Distances.PreMetric\nend\n\n@inline function Distances._evaluate(::Delta,a::AbstractVector{T},b::AbstractVector{T}) where {T}\n    @boundscheck if length(a) != length(b)\n        throw(DimensionMismatch(\"first array has length $(length(a)) which does not match the length of the second, $(length(b)).\"))\n    end\n    return a==b\nend\n\n@inline (dist::Delta)(a::AbstractArray,b::AbstractArray) = Distances._evaluate(dist,a,b)\n@inline (dist::Delta)(a::Number,b::Number) = a==b","category":"page"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  CurrentModule = KernelFunctions","category":"page"},{"location":"kernels/#Exponential-Kernels-1","page":"Kernel Functions","title":"Exponential Kernels","text":"","category":"section"},{"location":"kernels/#Exponential-Kernel-1","page":"Kernel Functions","title":"Exponential Kernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"The Exponential Kernel is defined as","category":"page"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xx) = expleft(-x-xright)","category":"page"},{"location":"kernels/#Square-Exponential-Kernel-1","page":"Kernel Functions","title":"Square Exponential Kernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"The Square Exponential Kernel is defined as ","category":"page"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xx) = expleft(-x-x^2right)","category":"page"},{"location":"kernels/#Gamma-Exponential-Kernel-1","page":"Kernel Functions","title":"Gamma Exponential Kernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xxgamma) = expleft(-x-x^2gammaright)","category":"page"},{"location":"kernels/#Matern-Kernels-1","page":"Kernel Functions","title":"Matern Kernels","text":"","category":"section"},{"location":"kernels/#Matern-Kernel-1","page":"Kernel Functions","title":"Matern Kernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xxnu) = frac2^1-nuGamma(nu)left(sqrt2nux-xright)K_nuleft(sqrt2nux-xright)","category":"page"},{"location":"kernels/#Matern-3/2-Kernel-1","page":"Kernel Functions","title":"Matern 3/2 Kernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xx) = left(1+sqrt3x-xright)expleft(sqrt3x-xright)","category":"page"},{"location":"kernels/#Matern-5/2-Kernel-1","page":"Kernel Functions","title":"Matern 5/2 Kernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xx) = left(1+sqrt5x-x+frac52x-x^2right)expleft(sqrt5x-xright)","category":"page"},{"location":"kernels/#Rational-Quadratic-1","page":"Kernel Functions","title":"Rational Quadratic","text":"","category":"section"},{"location":"kernels/#Rational-Quadratic-Kernel-1","page":"Kernel Functions","title":"Rational Quadratic Kernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xxalpha) = left(1+fracx-x^2alpharight)^-alpha","category":"page"},{"location":"kernels/#Gamma-Rational-Quadratic-Kernel-1","page":"Kernel Functions","title":"Gamma Rational Quadratic Kernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xxalphagamma) = left(1+fracx-x^2gammaalpharight)^-alpha","category":"page"},{"location":"kernels/#Polynomial-Kernels-1","page":"Kernel Functions","title":"Polynomial Kernels","text":"","category":"section"},{"location":"kernels/#LinearKernel-1","page":"Kernel Functions","title":"LinearKernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xxc) = langle xxrangle + c","category":"page"},{"location":"kernels/#PolynomialKernel-1","page":"Kernel Functions","title":"PolynomialKernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xxcd) = left(langle xxrangle + cright)^d","category":"page"},{"location":"kernels/#Constant-Kernels-1","page":"Kernel Functions","title":"Constant Kernels","text":"","category":"section"},{"location":"kernels/#ConstantKernel-1","page":"Kernel Functions","title":"ConstantKernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xxc) = c","category":"page"},{"location":"kernels/#WhiteKernel-1","page":"Kernel Functions","title":"WhiteKernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xx) = delta(x-x)","category":"page"},{"location":"kernels/#ZeroKernel-1","page":"Kernel Functions","title":"ZeroKernel","text":"","category":"section"},{"location":"kernels/#","page":"Kernel Functions","title":"Kernel Functions","text":"  k(xx) = 0","category":"page"},{"location":"api/#API-Library-1","page":"API","title":"API Library","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"","category":"page"},{"location":"api/#","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"api/#","page":"API","title":"API","text":"CurrentModule = KernelFunctions","category":"page"},{"location":"api/#Module-1","page":"API","title":"Module","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"KernelFunctions","category":"page"},{"location":"api/#Kernel-Functions-1","page":"API","title":"Kernel Functions","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"SqExponentialKernel\nExponentialKernel\nGammaExponentialKernel\nExponentiatedKernel\nMaternKernel\nMatern32Kernel\nMatern52Kernel\nLinearKernel\nPolynomialKernel\nRationalQuadraticKernel\nGammaRationalQuadraticKernel\nZeroKernel\nConstantKernel\nWhiteKernel","category":"page"},{"location":"api/#KernelFunctions.SqExponentialKernel","page":"API","title":"KernelFunctions.SqExponentialKernel","text":"SqExponentialKernel([ρ=1.0])\n\nThe squared exponential kernel is an isotropic Mercer kernel given by the formula:\n\n    κ(x,y) = exp(-ρ²‖x-y‖²)\n\nSee also ExponentialKernel for a related form of the kernel or GammaExponentialKernel for a generalization.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.ExponentialKernel","page":"API","title":"KernelFunctions.ExponentialKernel","text":"ExponentialKernel([ρ=1.0]) The exponential kernel is an isotropic Mercer kernel given by the formula:\n\n    κ(x,y) = exp(-ρ‖x-y‖)\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.GammaExponentialKernel","page":"API","title":"KernelFunctions.GammaExponentialKernel","text":"GammaExponentialKernel([ρ=1.0,[gamma=2.0]]) The γ-exponential kernel is an isotropic Mercer kernel given by the formula:\n\n    κ(x,y) = exp(-ρ^(2γ)‖x-y‖^(2γ))\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.ExponentiatedKernel","page":"API","title":"KernelFunctions.ExponentiatedKernel","text":"ExponentiatedKernel([ρ=1]) The exponentiated kernel is a Mercer kernel given by:\n\n    κ(x,y) = exp(ρ²xᵀy)\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.MaternKernel","page":"API","title":"KernelFunctions.MaternKernel","text":"MaternKernel([ρ=1.0,[ν=1.0]]) The matern kernel is an isotropic Mercer kernel given by the formula:\n\n    κ(x,y) = 2^{1-ν}/Γ(ν)*(√(2ν)‖x-y‖)^ν K_ν(√(2ν)‖x-y‖)\n\nFor ν=n+1/2, n=0,1,2,... it can be simplified and you should instead use ExponentialKernel for n=0, Matern32Kernel, for n=1, Matern52Kernel for n=2 and SqExponentialKernel for n=∞.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.Matern32Kernel","page":"API","title":"KernelFunctions.Matern32Kernel","text":"Matern32Kernel([ρ=1.0]) The matern 3/2 kernel is an isotropic Mercer kernel given by the formula:\n\n    κ(x,y) = (1+√(3)ρ‖x-y‖)exp(-√(3)ρ‖x-y‖)\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.Matern52Kernel","page":"API","title":"KernelFunctions.Matern52Kernel","text":"Matern52Kernel([ρ=1.0]) The matern 5/2 kernel is an isotropic Mercer kernel given by the formula:\n\n    κ(x,y) = (1+√(5)ρ‖x-y‖ + 5ρ²‖x-y‖^2/3)exp(-√(5)ρ‖x-y‖)\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.LinearKernel","page":"API","title":"KernelFunctions.LinearKernel","text":"LinearKernel([ρ=1.0,[c=0.0]]) The linear kernel is a Mercer kernel given by\n\n    κ(x,y) = ρ²xᵀy + c\n\nWhere c is a real number\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.PolynomialKernel","page":"API","title":"KernelFunctions.PolynomialKernel","text":"PolynomialKernel([ρ=1.0[,d=2.0[,c=0.0]]]) The polynomial kernel is a Mercer kernel given by\n\n    κ(x,y) = (ρ²xᵀy + c)^d\n\nWhere c is a real number, and d is a shape parameter bigger than 1\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.RationalQuadraticKernel","page":"API","title":"KernelFunctions.RationalQuadraticKernel","text":"RationalQuadraticKernel([ρ=1.0[,α=2.0]]) The rational-quadratic kernel is an isotropic Mercer kernel given by the formula:\n\n    κ(x,y)=(1+ρ²||x−y||²/α)^(-α)\n\nwhere α is a shape parameter of the Euclidean distance. Check GammaRationalQuadraticKernel for a generalization.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.GammaRationalQuadraticKernel","page":"API","title":"KernelFunctions.GammaRationalQuadraticKernel","text":"GammaRationalQuadraticKernel([ρ=1.0[,α=2.0[,γ=2.0]]]) The Gamma-rational-quadratic kernel is an isotropic Mercer kernel given by the formula:\n\n    κ(x,y)=(1+ρ^(2γ)||x−y||^(2γ)/α)^(-α)\n\nwhere α is a shape parameter of the Euclidean distance and γ is another shape parameter.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.ZeroKernel","page":"API","title":"KernelFunctions.ZeroKernel","text":"ZeroKernel([tr=IdentityTransform()])\n\nCreate a kernel always returning zero\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.ConstantKernel","page":"API","title":"KernelFunctions.ConstantKernel","text":"ConstantKernel([tr=IdentityTransform(),[c=1.0]])\n\n    κ(x,y) = c\n\nKernel function always returning a constant value c\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.WhiteKernel","page":"API","title":"KernelFunctions.WhiteKernel","text":"WhiteKernel([tr=IdentityTransform()])\n\n    κ(x,y) = δ(x,y)\n\nKernel function working as an equivalent to add white noise.\n\n\n\n\n\n","category":"type"},{"location":"api/#Kernel-Combinations-1","page":"API","title":"Kernel Combinations","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"KernelSum\nKernelProduct","category":"page"},{"location":"api/#KernelFunctions.KernelSum","page":"API","title":"KernelFunctions.KernelSum","text":"KernelSum(kernels::Array{Kernel};weights::Array{Real}=ones(length(kernels))) Create a positive weighted sum of kernels. One can also use the operator +\n\nk1 = SqExponentialKernel()\nk2 = LinearKernel()\nk = KernelSum([k1,k2])\nkernelmatrix(k,X) == kernelmatrix(k1,X).+kernelmatrix(k2,X)\nkernelmatrix(k,X) == kernelmatrix(k1+k2,X)\nkweighted = 0.5*k1 + 2.0*k2\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.KernelProduct","page":"API","title":"KernelFunctions.KernelProduct","text":"KernelProduct(kernels::Array{Kernel}) Create a multiplication of kernels. One can also use the operator *\n\nk1 = SqExponentialKernel()\nk2 = LinearKernel()\nk = KernelProduct([k1,k2])\nkernelmatrix(k,X) == kernelmatrix(k1,X).*kernelmatrix(k2,X)\nkernelmatrix(k,X) == kernelmatrix(k1*k2,X)\n\n\n\n\n\n","category":"type"},{"location":"api/#Transforms-1","page":"API","title":"Transforms","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Transform\nIdentityTransform\nScaleTransform\nLowRankTransform\nFunctionTransform\nChainTransform","category":"page"},{"location":"api/#KernelFunctions.Transform","page":"API","title":"KernelFunctions.Transform","text":"Abstract type defining a slice-wise transformation on an input matrix\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.IdentityTransform","page":"API","title":"KernelFunctions.IdentityTransform","text":"IdentityTransform Return exactly the input\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.ScaleTransform","page":"API","title":"KernelFunctions.ScaleTransform","text":"Scale Transform\n\n    l = 2.0\n    tr = ScaleTransform(l)\n    v = rand(3)\n    tr = ScaleTransform(v)\n\nMultiply every element of the matrix by l for a scalar Multiply every vector of observation by v element-wise for a vector\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.LowRankTransform","page":"API","title":"KernelFunctions.LowRankTransform","text":"LowRankTransform\n\n    P = rand(10,5)\n    tr = LowRankTransform(P)\n\nApply the low-rank projection realised by the matrix P The second dimension of P must match the number of features of the target.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.FunctionTransform","page":"API","title":"KernelFunctions.FunctionTransform","text":"FunctionTransform\n\n    f(x) = abs.(x)\n    tr = FunctionTransform(f)\n\nTake a function f as an argument which is going to act on each vector individually. Make sure that f is supposed to act on a vector by eventually using broadcasting For example f(x)=sin(x) -> f(x)=sin.(x)\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelFunctions.ChainTransform","page":"API","title":"KernelFunctions.ChainTransform","text":"Chain a series of transform, here t1 will be called first\n\n    t1 = ScaleTransform()\n    t2 = LowRankTransform(rand(3,4))\n    ct = ChainTransform([t1,t2]) #t1 will be called first\n    ct == t2∘t1\n\n\n\n\n\n","category":"type"},{"location":"api/#Functions-1","page":"API","title":"Functions","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"kernelmatrix\nkernelmatrix!\nkerneldiagmatrix\nkerneldiagmatrix!\nkernelpdmat\ntransform","category":"page"},{"location":"api/#KernelFunctions.kernelmatrix","page":"API","title":"KernelFunctions.kernelmatrix","text":"    kernelmatrix(κ::Kernel, X::Matrix ; obsdim::Int=2)\n    kernelmatrix(κ::Kernel, X::Matrix, Y::Matrix; obsdim::Int=2)\n\nCalculate the kernel matrix of X (and Y) with respect to kernel κ. obsdim=1 means the matrix X (and Y) has size #samples x #dimension obsdim=2 means the matrix X (and Y) has size #dimension x #samples\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelFunctions.kernelmatrix!","page":"API","title":"KernelFunctions.kernelmatrix!","text":"    kernelmatrix!(K::Matrix, κ::Kernel, X::Matrix; obsdim::Integer=2)\n    kernelmatrix!(K::Matrix, κ::Kernel, X::Matrix, Y::Matrix; obsdim::Integer=2)\n\nIn-place version of kernelmatrix where pre-allocated matrix K will be overwritten with the kernel matrix.\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelFunctions.kerneldiagmatrix","page":"API","title":"KernelFunctions.kerneldiagmatrix","text":"    kerneldiagmatrix(κ::Kernel, X::Matrix; obsdim::Int=2)\n\nCalculate the diagonal matrix of X with respect to kernel κ obsdim=1 means the matrix X has size #samples x #dimension obsdim=2 means the matrix X has size #dimension x #samples\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelFunctions.kerneldiagmatrix!","page":"API","title":"KernelFunctions.kerneldiagmatrix!","text":"    kerneldiagmatrix!(K::AbstractVector,κ::Kernel, X::Matrix; obsdim::Int=2)\n\nIn place version of kerneldiagmatrix\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelFunctions.kernelpdmat","page":"API","title":"KernelFunctions.kernelpdmat","text":"Compute a positive-definite matrix in the form of a `PDMat` matrix see [PDMats.jl]() with the cholesky decomposition precomputed\nThe algorithm recursively tries to add recursively a diagonal nugget until positive definiteness is achieved or that the noise is too big\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelFunctions.transform","page":"API","title":"KernelFunctions.transform","text":"    transform(t::Transform, X::AbstractMatrix)\n    transform(k::Kernel, X::AbstractMatrix)\n\nApply the transfomration t or k.transform on the input X\n\n\n\n\n\n","category":"function"},{"location":"api/#Index-1","page":"API","title":"Index","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Pages = [\"api.md\"]\nModule = [\"KernelFunctions\"]\nOrder = [:type, :function]","category":"page"},{"location":"theory/#","page":"Theory","title":"Theory","text":"See Wikipedia article","category":"page"},{"location":"transform/#Transform-1","page":"Transform","title":"Transform","text":"","category":"section"},{"location":"transform/#","page":"Transform","title":"Transform","text":"Transform is the object that takes care of transforming the input data before distances are being computed. It can be as standard as IdentityTransform returning the same input, can be a scalar with ScaleTransform multiplying the vectors by a scalar or a vector. There is a more general Transform: FunctionTransform that uses a function and apply it on each vector via mapslices. You can also create a pipeline of Transform via TransformChain. For example LowRankTransform(rand(10,5))∘ScaleTransform(2.0).","category":"page"},{"location":"transform/#","page":"Transform","title":"Transform","text":"One apply a transformation on a matrix or a vector via transform(t::Transform,v::AbstractVecOrMat)","category":"page"},{"location":"transform/#Transforms-:-1","page":"Transform","title":"Transforms :","text":"","category":"section"},{"location":"transform/#","page":"Transform","title":"Transform","text":"CurrentModule = KernelFunctions","category":"page"},{"location":"transform/#","page":"Transform","title":"Transform","text":"  IdentityTransform\n  ScaleTransform\n  LowRankTransform\n  FunctionTransform\n  ChainTransform","category":"page"},{"location":"userguide/#User-guide-1","page":"User Guide","title":"User guide","text":"","category":"section"},{"location":"userguide/#Kernel-creation-1","page":"User Guide","title":"Kernel creation","text":"","category":"section"},{"location":"userguide/#","page":"User Guide","title":"User Guide","text":"To create a kernel chose one of the kernels proposed, see Kernels, or create your own, see Creating Kernels For example to create a square exponential kernel","category":"page"},{"location":"userguide/#","page":"User Guide","title":"User Guide","text":"  k = SqExponentialKernel()","category":"page"},{"location":"userguide/#","page":"User Guide","title":"User Guide","text":"All kernels can take as argument a Transform object (see Transform) which is directly going to act on the inputs before it's processes. But it's also possible to simply give a scalar or a vector if all you are interested in is to modify the lengthscale, respectively for all dimensions or independently for each dimension.","category":"page"},{"location":"userguide/#Kernel-matrix-creation-1","page":"User Guide","title":"Kernel matrix creation","text":"","category":"section"},{"location":"userguide/#","page":"User Guide","title":"User Guide","text":"Matrix are created via the kernelmatrix function or kerneldiagmatrix. An important argument to give is the dimensionality of the input obsdim. It tells if the matrix is of the type # samples X # features (obsdim=1) or # features X # samples(obsdim=2) (similarly to Distances.jl) For example:","category":"page"},{"location":"userguide/#","page":"User Guide","title":"User Guide","text":"  k = SqExponentialKernel()\n  A = rand(10,5)\n  kernelmatrix(k,A,obsdim=1) # Return a 10x10 matrix\n  kernelmatrix(k,A,obsdim=2) # Return a 5x5 matrix","category":"page"},{"location":"userguide/#Kernel-manipulation-1","page":"User Guide","title":"Kernel manipulation","text":"","category":"section"},{"location":"userguide/#","page":"User Guide","title":"User Guide","text":"One can create combinations of kernels via KernelSum and KernelProduct or using simple operators + and *. For","category":"page"},{"location":"#KernelFunctions.jl-1","page":"Home","title":"KernelFunctions.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Model agnostic kernel functions compatible with automatic differentiation","category":"page"},{"location":"#","page":"Home","title":"Home","text":"KernelFunctions.jl is a general purpose kernel package. It aims at providing a flexible framework for creating kernels and manipulating them. The main goals of this package compared to its predecessors/concurrents in MLKernels.jl, Stheno.jl, GaussianProcesses.jl and AugmentedGaussianProcesses.jl are:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Automatic Differentation compatibility: all kernel functions should be differentiable via packages like ForwardDiff.jl or Zygote.jl\nFlexibility: operations between kernels should be fluid and easy without breaking.\nPlug-and-play: including the kernels before/after other steps should be straightforward.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The methodology of how kernels are computed is quite simple and is done in three phases :","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A Transform object is applied sample-wise on every sample\nThe pairwise matrix is computed using Distances.jl by using a Metric proper to each kernel\nThe Kernel function is applied element-wise on the pairwise matrix","category":"page"},{"location":"#","page":"Home","title":"Home","text":"For a quick introduction on how to use it go to User guide","category":"page"},{"location":"example/#Examples-(WIP)-1","page":"Examples","title":"Examples (WIP)","text":"","category":"section"},{"location":"example/#","page":"Examples","title":"Examples","text":"Here are a few examples of known complex kernels and how to do them. Or how to use kernels in a certain context","category":"page"},{"location":"example/#Kernel-Ridge-Regression-1","page":"Examples","title":"Kernel Ridge Regression","text":"","category":"section"},{"location":"example/#","page":"Examples","title":"Examples","text":"Make a simple example of kernel ridge regression","category":"page"},{"location":"example/#Gaussian-Process-Regression-1","page":"Examples","title":"Gaussian Process Regression","text":"","category":"section"},{"location":"example/#","page":"Examples","title":"Examples","text":"Make a simple example of gaussian process regression","category":"page"},{"location":"example/#Deep-Kernel-Learning-1","page":"Examples","title":"Deep Kernel Learning","text":"","category":"section"},{"location":"example/#","page":"Examples","title":"Examples","text":"Put a Flux neural net in front of the kernel cf. Wilson paper","category":"page"},{"location":"example/#Kernel-Selection-1","page":"Examples","title":"Kernel Selection","text":"","category":"section"},{"location":"example/#","page":"Examples","title":"Examples","text":"Create a large collection of kernels and optimize the weights cf AISTATS 2018 paper","category":"page"}]
}
